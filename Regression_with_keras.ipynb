{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression with keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEYt5nZL+tfZvbhpWKniZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohmaed7777/Deep-Neural-Network-with-Keras/blob/master/Regression_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m39ECu2qIjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd12LmqhqOMp",
        "colab_type": "text"
      },
      "source": [
        "**The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:**\n",
        "\n",
        "**1. Cement**\n",
        "\n",
        "**2. Blast Furnace Slag**\n",
        "\n",
        "**3. Fly Ash**\n",
        "\n",
        "**4. Water**\n",
        "\n",
        "**5. Superplasticizer**\n",
        "\n",
        "**6. Coarse Aggregate**\n",
        "\n",
        "**7. Fine Aggregate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHbrGqHsrQNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "8fd6db80-7af1-44b4-ec4e-8ddd86113425"
      },
      "source": [
        "# Download the dataset \n",
        "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
        "concrete_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  ...  Fine Aggregate  Age  Strength\n",
              "0   540.0                 0.0      0.0  ...           676.0   28     79.99\n",
              "1   540.0                 0.0      0.0  ...           676.0   28     61.89\n",
              "2   332.5               142.5      0.0  ...           594.0  270     40.27\n",
              "3   332.5               142.5      0.0  ...           594.0  365     41.05\n",
              "4   198.6               132.4      0.0  ...           825.5  360     44.30\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg8EIDQ_rjay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb27fcbf-a6b1-47c9-de7b-3066114f3e10"
      },
      "source": [
        "concrete_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1030, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW5qrr27roBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "573b8e72-be6b-4572-ec87-4dd0aaffdbb2"
      },
      "source": [
        "concrete_data.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>281.167864</td>\n",
              "      <td>73.895825</td>\n",
              "      <td>54.188350</td>\n",
              "      <td>181.567282</td>\n",
              "      <td>6.204660</td>\n",
              "      <td>972.918932</td>\n",
              "      <td>773.580485</td>\n",
              "      <td>45.662136</td>\n",
              "      <td>35.817961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104.506364</td>\n",
              "      <td>86.279342</td>\n",
              "      <td>63.997004</td>\n",
              "      <td>21.354219</td>\n",
              "      <td>5.973841</td>\n",
              "      <td>77.753954</td>\n",
              "      <td>80.175980</td>\n",
              "      <td>63.169912</td>\n",
              "      <td>16.705742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>121.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>594.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>192.375000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>932.000000</td>\n",
              "      <td>730.950000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>23.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>272.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>968.000000</td>\n",
              "      <td>779.500000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>34.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>142.950000</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>1029.400000</td>\n",
              "      <td>824.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>46.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>540.000000</td>\n",
              "      <td>359.400000</td>\n",
              "      <td>200.100000</td>\n",
              "      <td>247.000000</td>\n",
              "      <td>32.200000</td>\n",
              "      <td>1145.000000</td>\n",
              "      <td>992.600000</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>82.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Cement  Blast Furnace Slag  ...          Age     Strength\n",
              "count  1030.000000         1030.000000  ...  1030.000000  1030.000000\n",
              "mean    281.167864           73.895825  ...    45.662136    35.817961\n",
              "std     104.506364           86.279342  ...    63.169912    16.705742\n",
              "min     102.000000            0.000000  ...     1.000000     2.330000\n",
              "25%     192.375000            0.000000  ...     7.000000    23.710000\n",
              "50%     272.900000           22.000000  ...    28.000000    34.445000\n",
              "75%     350.000000          142.950000  ...    56.000000    46.135000\n",
              "max     540.000000          359.400000  ...   365.000000    82.600000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9rEo3UirsMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "7a6adecc-f0f4-4852-ca6f-0646bfcc8c1e"
      },
      "source": [
        "concrete_data.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement                0\n",
              "Blast Furnace Slag    0\n",
              "Fly Ash               0\n",
              "Water                 0\n",
              "Superplasticizer      0\n",
              "Coarse Aggregate      0\n",
              "Fine Aggregate        0\n",
              "Age                   0\n",
              "Strength              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUbKFWVJq_aD",
        "colab_type": "text"
      },
      "source": [
        "# **Split our data into predictors and targets:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4E0ye6QrvbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concrete_data_columns = concrete_data.columns\n",
        "\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
        "target = concrete_data['Strength'] # Strength column"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND3cQAMIr_0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "677ad152-5edf-4d25-f5b1-62bf08434186"
      },
      "source": [
        "# Let's to check our predictors and targets dataframe:\n",
        "predictors.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  ...  Coarse Aggregate  Fine Aggregate  Age\n",
              "0   540.0                 0.0      0.0  ...            1040.0           676.0   28\n",
              "1   540.0                 0.0      0.0  ...            1055.0           676.0   28\n",
              "2   332.5               142.5      0.0  ...             932.0           594.0  270\n",
              "3   332.5               142.5      0.0  ...             932.0           594.0  365\n",
              "4   198.6               132.4      0.0  ...             978.4           825.5  360\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yg9snohsXT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "04ed27ab-8afe-4979-90f3-dbf098add7dd"
      },
      "source": [
        "target.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    79.99\n",
              "1    61.89\n",
              "2    40.27\n",
              "3    41.05\n",
              "4    44.30\n",
              "Name: Strength, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DiqFcUyslFT",
        "colab_type": "text"
      },
      "source": [
        "Finally, the last step is to normalize the data by substracting the mean and dividing by the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCzozw3fsbUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "16cbef3e-e9bd-42ee-cd59-cf03458a7864"
      },
      "source": [
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
        "predictors_norm.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Cement  Blast Furnace Slag  ...  Fine Aggregate       Age\n",
              "0  2.476712           -0.856472  ...       -1.217079 -0.279597\n",
              "1  2.476712           -0.856472  ...       -1.217079 -0.279597\n",
              "2  0.491187            0.795140  ...       -2.239829  3.551340\n",
              "3  0.491187            0.795140  ...       -2.239829  5.055221\n",
              "4 -0.790075            0.678079  ...        0.647569  4.976069\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNFT_0UWs_dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d4bb4a3-ce68-4bee-99a7-1f3322761141"
      },
      "source": [
        "predictors_norm.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1030, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p70jtBYvtKek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's save the number of predictors to n_cols since we will need this number\n",
        "# when building our network.\n",
        "n_cols = predictors_norm.shape[1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rN4jcZ7tuy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c06a77d-514c-4a3b-f8fe-ec91fb267751"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXAEBi_Vt186",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JEeCPBxuHMN",
        "colab_type": "text"
      },
      "source": [
        "# **Build the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNQksFl0uFjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define regression model: \n",
        "def regression_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1000, activation='relu', input_shape=(n_cols,)))\n",
        "  model.add(Dense(1000, activation='relu'))\n",
        "  model.add(Dense(1000, activation='relu'))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "  # Compile model \n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58qA4rFLvmhF",
        "colab_type": "text"
      },
      "source": [
        "# **Train the Test the Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfmcXLZqviHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "model = regression_model() "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT1UbzAiwB5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "433e99a3-85ae-4b7d-8a40-10920be758c5"
      },
      "source": [
        "# fit the model \n",
        "model.fit(predictors_norm, target, validation_split=0.3, epochs=10000, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 721 samples, validate on 309 samples\n",
            "Epoch 1/10000\n",
            " - 1s - loss: 636.9615 - val_loss: 237.8510\n",
            "Epoch 2/10000\n",
            " - 1s - loss: 237.2225 - val_loss: 251.8145\n",
            "Epoch 3/10000\n",
            " - 1s - loss: 161.0647 - val_loss: 205.4778\n",
            "Epoch 4/10000\n",
            " - 1s - loss: 120.4320 - val_loss: 224.6154\n",
            "Epoch 5/10000\n",
            " - 1s - loss: 90.4226 - val_loss: 225.8039\n",
            "Epoch 6/10000\n",
            " - 1s - loss: 71.7072 - val_loss: 231.3588\n",
            "Epoch 7/10000\n",
            " - 1s - loss: 56.6616 - val_loss: 209.4070\n",
            "Epoch 8/10000\n",
            " - 1s - loss: 48.2284 - val_loss: 179.3415\n",
            "Epoch 9/10000\n",
            " - 1s - loss: 44.0185 - val_loss: 119.4817\n",
            "Epoch 10/10000\n",
            " - 1s - loss: 43.4001 - val_loss: 164.7855\n",
            "Epoch 11/10000\n",
            " - 1s - loss: 32.4021 - val_loss: 136.3029\n",
            "Epoch 12/10000\n",
            " - 1s - loss: 32.1307 - val_loss: 131.0554\n",
            "Epoch 13/10000\n",
            " - 1s - loss: 31.8292 - val_loss: 123.2159\n",
            "Epoch 14/10000\n",
            " - 1s - loss: 27.4547 - val_loss: 201.5597\n",
            "Epoch 15/10000\n",
            " - 1s - loss: 25.9739 - val_loss: 155.6230\n",
            "Epoch 16/10000\n",
            " - 1s - loss: 21.6441 - val_loss: 151.0229\n",
            "Epoch 17/10000\n",
            " - 1s - loss: 19.4401 - val_loss: 101.1139\n",
            "Epoch 18/10000\n",
            " - 1s - loss: 24.2084 - val_loss: 88.4215\n",
            "Epoch 19/10000\n",
            " - 1s - loss: 23.6909 - val_loss: 126.7256\n",
            "Epoch 20/10000\n",
            " - 1s - loss: 20.1316 - val_loss: 119.1652\n",
            "Epoch 21/10000\n",
            " - 1s - loss: 18.7821 - val_loss: 119.5358\n",
            "Epoch 22/10000\n",
            " - 1s - loss: 17.0817 - val_loss: 132.3758\n",
            "Epoch 23/10000\n",
            " - 1s - loss: 18.6076 - val_loss: 142.2218\n",
            "Epoch 24/10000\n",
            " - 1s - loss: 21.6616 - val_loss: 138.9650\n",
            "Epoch 25/10000\n",
            " - 1s - loss: 22.1965 - val_loss: 120.7154\n",
            "Epoch 26/10000\n",
            " - 1s - loss: 19.0099 - val_loss: 135.9116\n",
            "Epoch 27/10000\n",
            " - 1s - loss: 16.0877 - val_loss: 109.6778\n",
            "Epoch 28/10000\n",
            " - 1s - loss: 18.1796 - val_loss: 93.3175\n",
            "Epoch 29/10000\n",
            " - 1s - loss: 20.1837 - val_loss: 144.8869\n",
            "Epoch 30/10000\n",
            " - 1s - loss: 16.0955 - val_loss: 128.3827\n",
            "Epoch 31/10000\n",
            " - 1s - loss: 16.8530 - val_loss: 161.0373\n",
            "Epoch 32/10000\n",
            " - 1s - loss: 15.1028 - val_loss: 123.5140\n",
            "Epoch 33/10000\n",
            " - 1s - loss: 16.0829 - val_loss: 184.8999\n",
            "Epoch 34/10000\n",
            " - 1s - loss: 21.6403 - val_loss: 111.9866\n",
            "Epoch 35/10000\n",
            " - 1s - loss: 17.3518 - val_loss: 105.1981\n",
            "Epoch 36/10000\n",
            " - 1s - loss: 13.8986 - val_loss: 115.5847\n",
            "Epoch 37/10000\n",
            " - 1s - loss: 15.0188 - val_loss: 102.6352\n",
            "Epoch 38/10000\n",
            " - 1s - loss: 15.2065 - val_loss: 153.5045\n",
            "Epoch 39/10000\n",
            " - 1s - loss: 18.9233 - val_loss: 179.2400\n",
            "Epoch 40/10000\n",
            " - 1s - loss: 14.6900 - val_loss: 154.5921\n",
            "Epoch 41/10000\n",
            " - 1s - loss: 15.6933 - val_loss: 79.3071\n",
            "Epoch 42/10000\n",
            " - 1s - loss: 13.7216 - val_loss: 92.4196\n",
            "Epoch 43/10000\n",
            " - 1s - loss: 16.6274 - val_loss: 107.2608\n",
            "Epoch 44/10000\n",
            " - 1s - loss: 12.8886 - val_loss: 110.8446\n",
            "Epoch 45/10000\n",
            " - 1s - loss: 11.7092 - val_loss: 97.2194\n",
            "Epoch 46/10000\n",
            " - 1s - loss: 13.4037 - val_loss: 97.3183\n",
            "Epoch 47/10000\n",
            " - 1s - loss: 12.3252 - val_loss: 142.2533\n",
            "Epoch 48/10000\n",
            " - 1s - loss: 11.5865 - val_loss: 132.5535\n",
            "Epoch 49/10000\n",
            " - 1s - loss: 15.1887 - val_loss: 67.1151\n",
            "Epoch 50/10000\n",
            " - 1s - loss: 14.1851 - val_loss: 98.3599\n",
            "Epoch 51/10000\n",
            " - 1s - loss: 14.5048 - val_loss: 123.9503\n",
            "Epoch 52/10000\n",
            " - 1s - loss: 11.5329 - val_loss: 120.7731\n",
            "Epoch 53/10000\n",
            " - 1s - loss: 12.1583 - val_loss: 89.1883\n",
            "Epoch 54/10000\n",
            " - 1s - loss: 15.4435 - val_loss: 140.5659\n",
            "Epoch 55/10000\n",
            " - 1s - loss: 15.3064 - val_loss: 144.1182\n",
            "Epoch 56/10000\n",
            " - 1s - loss: 14.7341 - val_loss: 150.5336\n",
            "Epoch 57/10000\n",
            " - 1s - loss: 11.2821 - val_loss: 119.6242\n",
            "Epoch 58/10000\n",
            " - 1s - loss: 12.4168 - val_loss: 146.0465\n",
            "Epoch 59/10000\n",
            " - 1s - loss: 16.6145 - val_loss: 132.3792\n",
            "Epoch 60/10000\n",
            " - 1s - loss: 12.2246 - val_loss: 149.1299\n",
            "Epoch 61/10000\n",
            " - 1s - loss: 12.9915 - val_loss: 147.6192\n",
            "Epoch 62/10000\n",
            " - 1s - loss: 10.5079 - val_loss: 83.8761\n",
            "Epoch 63/10000\n",
            " - 1s - loss: 12.4815 - val_loss: 107.9664\n",
            "Epoch 64/10000\n",
            " - 1s - loss: 11.1201 - val_loss: 109.7955\n",
            "Epoch 65/10000\n",
            " - 1s - loss: 13.9528 - val_loss: 116.7208\n",
            "Epoch 66/10000\n",
            " - 1s - loss: 13.0743 - val_loss: 99.5205\n",
            "Epoch 67/10000\n",
            " - 1s - loss: 10.7886 - val_loss: 105.4636\n",
            "Epoch 68/10000\n",
            " - 1s - loss: 9.6097 - val_loss: 101.0316\n",
            "Epoch 69/10000\n",
            " - 1s - loss: 10.5052 - val_loss: 111.0399\n",
            "Epoch 70/10000\n",
            " - 1s - loss: 8.8679 - val_loss: 99.0068\n",
            "Epoch 71/10000\n",
            " - 1s - loss: 15.1570 - val_loss: 77.8294\n",
            "Epoch 72/10000\n",
            " - 1s - loss: 17.4539 - val_loss: 136.6120\n",
            "Epoch 73/10000\n",
            " - 1s - loss: 13.4646 - val_loss: 138.5949\n",
            "Epoch 74/10000\n",
            " - 1s - loss: 10.5550 - val_loss: 116.8791\n",
            "Epoch 75/10000\n",
            " - 1s - loss: 9.0007 - val_loss: 115.5109\n",
            "Epoch 76/10000\n",
            " - 1s - loss: 9.0115 - val_loss: 120.0840\n",
            "Epoch 77/10000\n",
            " - 1s - loss: 10.4630 - val_loss: 145.6334\n",
            "Epoch 78/10000\n",
            " - 1s - loss: 11.1679 - val_loss: 179.2396\n",
            "Epoch 79/10000\n",
            " - 1s - loss: 13.1456 - val_loss: 119.3653\n",
            "Epoch 80/10000\n",
            " - 1s - loss: 12.2802 - val_loss: 94.8516\n",
            "Epoch 81/10000\n",
            " - 1s - loss: 9.2647 - val_loss: 142.9069\n",
            "Epoch 82/10000\n",
            " - 1s - loss: 11.5564 - val_loss: 132.3762\n",
            "Epoch 83/10000\n",
            " - 1s - loss: 10.8991 - val_loss: 121.2559\n",
            "Epoch 84/10000\n",
            " - 1s - loss: 11.0783 - val_loss: 110.6432\n",
            "Epoch 85/10000\n",
            " - 1s - loss: 9.3613 - val_loss: 112.9940\n",
            "Epoch 86/10000\n",
            " - 1s - loss: 9.4377 - val_loss: 131.9449\n",
            "Epoch 87/10000\n",
            " - 1s - loss: 11.1121 - val_loss: 111.3565\n",
            "Epoch 88/10000\n",
            " - 1s - loss: 12.7323 - val_loss: 132.7883\n",
            "Epoch 89/10000\n",
            " - 1s - loss: 11.2075 - val_loss: 137.1049\n",
            "Epoch 90/10000\n",
            " - 1s - loss: 11.3499 - val_loss: 141.3862\n",
            "Epoch 91/10000\n",
            " - 1s - loss: 9.1162 - val_loss: 150.8146\n",
            "Epoch 92/10000\n",
            " - 1s - loss: 9.7068 - val_loss: 130.7514\n",
            "Epoch 93/10000\n",
            " - 1s - loss: 9.5843 - val_loss: 186.9462\n",
            "Epoch 94/10000\n",
            " - 1s - loss: 9.3784 - val_loss: 119.1569\n",
            "Epoch 95/10000\n",
            " - 1s - loss: 8.3753 - val_loss: 137.7475\n",
            "Epoch 96/10000\n",
            " - 1s - loss: 9.0788 - val_loss: 130.6990\n",
            "Epoch 97/10000\n",
            " - 1s - loss: 9.5709 - val_loss: 160.8481\n",
            "Epoch 98/10000\n",
            " - 1s - loss: 9.1819 - val_loss: 125.1210\n",
            "Epoch 99/10000\n",
            " - 1s - loss: 10.5504 - val_loss: 115.9572\n",
            "Epoch 100/10000\n",
            " - 1s - loss: 10.8773 - val_loss: 126.0277\n",
            "Epoch 101/10000\n",
            " - 1s - loss: 10.4038 - val_loss: 129.5751\n",
            "Epoch 102/10000\n",
            " - 1s - loss: 9.0853 - val_loss: 151.9385\n",
            "Epoch 103/10000\n",
            " - 1s - loss: 10.6337 - val_loss: 142.9822\n",
            "Epoch 104/10000\n",
            " - 1s - loss: 10.9541 - val_loss: 129.1082\n",
            "Epoch 105/10000\n",
            " - 1s - loss: 12.5778 - val_loss: 142.5187\n",
            "Epoch 106/10000\n",
            " - 1s - loss: 8.8436 - val_loss: 142.8508\n",
            "Epoch 107/10000\n",
            " - 1s - loss: 10.9953 - val_loss: 156.2366\n",
            "Epoch 108/10000\n",
            " - 1s - loss: 11.8440 - val_loss: 157.6343\n",
            "Epoch 109/10000\n",
            " - 1s - loss: 12.1480 - val_loss: 138.1906\n",
            "Epoch 110/10000\n",
            " - 1s - loss: 8.3304 - val_loss: 143.6186\n",
            "Epoch 111/10000\n",
            " - 1s - loss: 11.3766 - val_loss: 131.5005\n",
            "Epoch 112/10000\n",
            " - 1s - loss: 15.5495 - val_loss: 93.9991\n",
            "Epoch 113/10000\n",
            " - 1s - loss: 9.7177 - val_loss: 158.4804\n",
            "Epoch 114/10000\n",
            " - 1s - loss: 10.5955 - val_loss: 153.0511\n",
            "Epoch 115/10000\n",
            " - 1s - loss: 10.8902 - val_loss: 111.9985\n",
            "Epoch 116/10000\n",
            " - 1s - loss: 9.6354 - val_loss: 141.0802\n",
            "Epoch 117/10000\n",
            " - 1s - loss: 8.8394 - val_loss: 139.4819\n",
            "Epoch 118/10000\n",
            " - 1s - loss: 8.9382 - val_loss: 121.4065\n",
            "Epoch 119/10000\n",
            " - 1s - loss: 10.1754 - val_loss: 108.0397\n",
            "Epoch 120/10000\n",
            " - 1s - loss: 15.7387 - val_loss: 130.8913\n",
            "Epoch 121/10000\n",
            " - 1s - loss: 8.9857 - val_loss: 166.1277\n",
            "Epoch 122/10000\n",
            " - 1s - loss: 10.2435 - val_loss: 130.7532\n",
            "Epoch 123/10000\n",
            " - 1s - loss: 9.3195 - val_loss: 149.1570\n",
            "Epoch 124/10000\n",
            " - 1s - loss: 9.0634 - val_loss: 139.8177\n",
            "Epoch 125/10000\n",
            " - 1s - loss: 10.9508 - val_loss: 155.7668\n",
            "Epoch 126/10000\n",
            " - 1s - loss: 12.1698 - val_loss: 150.4549\n",
            "Epoch 127/10000\n",
            " - 1s - loss: 9.7436 - val_loss: 117.3359\n",
            "Epoch 128/10000\n",
            " - 1s - loss: 9.4576 - val_loss: 158.5491\n",
            "Epoch 129/10000\n",
            " - 1s - loss: 6.9998 - val_loss: 118.7048\n",
            "Epoch 130/10000\n",
            " - 1s - loss: 8.2105 - val_loss: 150.3914\n",
            "Epoch 131/10000\n",
            " - 1s - loss: 8.9872 - val_loss: 130.6340\n",
            "Epoch 132/10000\n",
            " - 1s - loss: 8.3937 - val_loss: 135.5419\n",
            "Epoch 133/10000\n",
            " - 1s - loss: 8.0029 - val_loss: 128.7039\n",
            "Epoch 134/10000\n",
            " - 1s - loss: 8.6659 - val_loss: 117.8319\n",
            "Epoch 135/10000\n",
            " - 1s - loss: 7.4241 - val_loss: 142.5458\n",
            "Epoch 136/10000\n",
            " - 1s - loss: 8.4472 - val_loss: 134.2819\n",
            "Epoch 137/10000\n",
            " - 1s - loss: 8.3601 - val_loss: 147.0860\n",
            "Epoch 138/10000\n",
            " - 1s - loss: 7.5339 - val_loss: 117.5141\n",
            "Epoch 139/10000\n",
            " - 1s - loss: 14.3048 - val_loss: 124.4690\n",
            "Epoch 140/10000\n",
            " - 1s - loss: 8.6120 - val_loss: 183.4635\n",
            "Epoch 141/10000\n",
            " - 1s - loss: 7.5772 - val_loss: 149.0168\n",
            "Epoch 142/10000\n",
            " - 1s - loss: 6.6889 - val_loss: 134.9384\n",
            "Epoch 143/10000\n",
            " - 1s - loss: 7.2763 - val_loss: 142.7927\n",
            "Epoch 144/10000\n",
            " - 1s - loss: 7.8686 - val_loss: 140.9789\n",
            "Epoch 145/10000\n",
            " - 1s - loss: 7.4285 - val_loss: 121.8711\n",
            "Epoch 146/10000\n",
            " - 1s - loss: 12.9047 - val_loss: 139.8643\n",
            "Epoch 147/10000\n",
            " - 1s - loss: 9.1218 - val_loss: 117.6526\n",
            "Epoch 148/10000\n",
            " - 1s - loss: 9.2984 - val_loss: 179.6352\n",
            "Epoch 149/10000\n",
            " - 1s - loss: 7.0366 - val_loss: 149.6126\n",
            "Epoch 150/10000\n",
            " - 1s - loss: 8.5133 - val_loss: 121.6869\n",
            "Epoch 151/10000\n",
            " - 1s - loss: 8.8857 - val_loss: 126.3157\n",
            "Epoch 152/10000\n",
            " - 1s - loss: 10.4709 - val_loss: 114.6138\n",
            "Epoch 153/10000\n",
            " - 1s - loss: 8.2883 - val_loss: 143.1866\n",
            "Epoch 154/10000\n",
            " - 1s - loss: 7.8479 - val_loss: 137.0810\n",
            "Epoch 155/10000\n",
            " - 1s - loss: 8.4484 - val_loss: 148.4844\n",
            "Epoch 156/10000\n",
            " - 1s - loss: 10.7014 - val_loss: 131.7600\n",
            "Epoch 157/10000\n",
            " - 1s - loss: 9.0620 - val_loss: 141.7427\n",
            "Epoch 158/10000\n",
            " - 1s - loss: 7.4578 - val_loss: 128.8028\n",
            "Epoch 159/10000\n",
            " - 1s - loss: 7.3755 - val_loss: 140.8947\n",
            "Epoch 160/10000\n",
            " - 1s - loss: 7.3286 - val_loss: 138.4854\n",
            "Epoch 161/10000\n",
            " - 1s - loss: 6.2105 - val_loss: 153.8978\n",
            "Epoch 162/10000\n",
            " - 1s - loss: 7.1544 - val_loss: 145.3041\n",
            "Epoch 163/10000\n",
            " - 1s - loss: 6.9497 - val_loss: 155.6006\n",
            "Epoch 164/10000\n",
            " - 1s - loss: 6.7327 - val_loss: 174.2563\n",
            "Epoch 165/10000\n",
            " - 1s - loss: 7.5013 - val_loss: 144.1810\n",
            "Epoch 166/10000\n",
            " - 1s - loss: 11.7443 - val_loss: 189.3738\n",
            "Epoch 167/10000\n",
            " - 1s - loss: 14.5572 - val_loss: 114.7564\n",
            "Epoch 168/10000\n",
            " - 1s - loss: 8.8832 - val_loss: 138.6109\n",
            "Epoch 169/10000\n",
            " - 1s - loss: 6.8472 - val_loss: 137.0625\n",
            "Epoch 170/10000\n",
            " - 1s - loss: 6.3517 - val_loss: 142.5862\n",
            "Epoch 171/10000\n",
            " - 1s - loss: 5.6132 - val_loss: 134.3717\n",
            "Epoch 172/10000\n",
            " - 1s - loss: 7.2936 - val_loss: 140.4977\n",
            "Epoch 173/10000\n",
            " - 1s - loss: 6.1721 - val_loss: 162.8864\n",
            "Epoch 174/10000\n",
            " - 1s - loss: 6.7234 - val_loss: 144.0686\n",
            "Epoch 175/10000\n",
            " - 1s - loss: 8.6063 - val_loss: 162.5987\n",
            "Epoch 176/10000\n",
            " - 1s - loss: 8.0501 - val_loss: 181.0685\n",
            "Epoch 177/10000\n",
            " - 1s - loss: 8.7318 - val_loss: 96.6147\n",
            "Epoch 178/10000\n",
            " - 1s - loss: 13.7912 - val_loss: 142.9290\n",
            "Epoch 179/10000\n",
            " - 1s - loss: 9.5174 - val_loss: 131.2475\n",
            "Epoch 180/10000\n",
            " - 1s - loss: 8.5640 - val_loss: 140.3231\n",
            "Epoch 181/10000\n",
            " - 1s - loss: 8.1262 - val_loss: 161.1876\n",
            "Epoch 182/10000\n",
            " - 1s - loss: 7.7828 - val_loss: 146.9088\n",
            "Epoch 183/10000\n",
            " - 1s - loss: 7.3699 - val_loss: 183.4059\n",
            "Epoch 184/10000\n",
            " - 1s - loss: 7.6637 - val_loss: 171.2897\n",
            "Epoch 185/10000\n",
            " - 1s - loss: 7.4528 - val_loss: 153.9111\n",
            "Epoch 186/10000\n",
            " - 1s - loss: 7.9243 - val_loss: 134.7629\n",
            "Epoch 187/10000\n",
            " - 1s - loss: 8.3505 - val_loss: 153.6435\n",
            "Epoch 188/10000\n",
            " - 1s - loss: 7.7798 - val_loss: 177.4437\n",
            "Epoch 189/10000\n",
            " - 1s - loss: 6.0596 - val_loss: 163.0006\n",
            "Epoch 190/10000\n",
            " - 1s - loss: 7.4820 - val_loss: 175.1220\n",
            "Epoch 191/10000\n",
            " - 1s - loss: 6.6581 - val_loss: 149.9508\n",
            "Epoch 192/10000\n",
            " - 1s - loss: 8.0793 - val_loss: 191.1464\n",
            "Epoch 193/10000\n",
            " - 1s - loss: 6.7334 - val_loss: 147.3288\n",
            "Epoch 194/10000\n",
            " - 1s - loss: 6.8218 - val_loss: 156.9399\n",
            "Epoch 195/10000\n",
            " - 1s - loss: 8.9312 - val_loss: 135.2488\n",
            "Epoch 196/10000\n",
            " - 1s - loss: 9.6242 - val_loss: 182.5209\n",
            "Epoch 197/10000\n",
            " - 1s - loss: 8.7938 - val_loss: 156.1293\n",
            "Epoch 198/10000\n",
            " - 1s - loss: 9.2201 - val_loss: 164.8659\n",
            "Epoch 199/10000\n",
            " - 1s - loss: 7.1554 - val_loss: 153.0302\n",
            "Epoch 200/10000\n",
            " - 1s - loss: 6.3904 - val_loss: 174.0599\n",
            "Epoch 201/10000\n",
            " - 1s - loss: 5.7275 - val_loss: 150.1767\n",
            "Epoch 202/10000\n",
            " - 1s - loss: 6.8374 - val_loss: 143.0093\n",
            "Epoch 203/10000\n",
            " - 1s - loss: 5.6733 - val_loss: 128.1013\n",
            "Epoch 204/10000\n",
            " - 1s - loss: 7.7125 - val_loss: 121.1880\n",
            "Epoch 205/10000\n",
            " - 1s - loss: 5.7270 - val_loss: 147.7569\n",
            "Epoch 206/10000\n",
            " - 1s - loss: 5.4622 - val_loss: 157.4817\n",
            "Epoch 207/10000\n",
            " - 1s - loss: 5.5075 - val_loss: 147.7896\n",
            "Epoch 208/10000\n",
            " - 1s - loss: 6.0902 - val_loss: 143.6272\n",
            "Epoch 209/10000\n",
            " - 1s - loss: 5.5510 - val_loss: 165.3408\n",
            "Epoch 210/10000\n",
            " - 1s - loss: 6.2888 - val_loss: 137.5178\n",
            "Epoch 211/10000\n",
            " - 1s - loss: 7.4285 - val_loss: 138.9810\n",
            "Epoch 212/10000\n",
            " - 1s - loss: 6.3735 - val_loss: 160.3835\n",
            "Epoch 213/10000\n",
            " - 1s - loss: 5.3727 - val_loss: 158.0709\n",
            "Epoch 214/10000\n",
            " - 1s - loss: 7.0336 - val_loss: 160.4301\n",
            "Epoch 215/10000\n",
            " - 1s - loss: 7.9303 - val_loss: 184.9148\n",
            "Epoch 216/10000\n",
            " - 1s - loss: 8.1310 - val_loss: 164.3421\n",
            "Epoch 217/10000\n",
            " - 1s - loss: 7.4389 - val_loss: 151.7534\n",
            "Epoch 218/10000\n",
            " - 1s - loss: 6.4752 - val_loss: 178.6434\n",
            "Epoch 219/10000\n",
            " - 1s - loss: 6.0578 - val_loss: 148.8705\n",
            "Epoch 220/10000\n",
            " - 1s - loss: 6.5481 - val_loss: 138.5191\n",
            "Epoch 221/10000\n",
            " - 1s - loss: 10.4526 - val_loss: 198.9375\n",
            "Epoch 222/10000\n",
            " - 1s - loss: 8.4184 - val_loss: 170.0553\n",
            "Epoch 223/10000\n",
            " - 1s - loss: 7.1498 - val_loss: 127.4134\n",
            "Epoch 224/10000\n",
            " - 1s - loss: 8.5791 - val_loss: 131.9150\n",
            "Epoch 225/10000\n",
            " - 1s - loss: 5.7510 - val_loss: 170.7931\n",
            "Epoch 226/10000\n",
            " - 1s - loss: 6.6884 - val_loss: 147.2610\n",
            "Epoch 227/10000\n",
            " - 1s - loss: 7.0733 - val_loss: 180.9195\n",
            "Epoch 228/10000\n",
            " - 1s - loss: 6.0860 - val_loss: 153.6074\n",
            "Epoch 229/10000\n",
            " - 1s - loss: 5.1543 - val_loss: 152.9939\n",
            "Epoch 230/10000\n",
            " - 1s - loss: 6.5802 - val_loss: 144.8950\n",
            "Epoch 231/10000\n",
            " - 1s - loss: 9.3214 - val_loss: 123.8716\n",
            "Epoch 232/10000\n",
            " - 1s - loss: 8.4495 - val_loss: 184.1200\n",
            "Epoch 233/10000\n",
            " - 1s - loss: 7.3204 - val_loss: 128.2965\n",
            "Epoch 234/10000\n",
            " - 1s - loss: 6.6748 - val_loss: 145.9410\n",
            "Epoch 235/10000\n",
            " - 1s - loss: 6.0143 - val_loss: 155.5050\n",
            "Epoch 236/10000\n",
            " - 1s - loss: 6.2355 - val_loss: 155.2091\n",
            "Epoch 237/10000\n",
            " - 1s - loss: 6.7639 - val_loss: 150.7920\n",
            "Epoch 238/10000\n",
            " - 1s - loss: 6.4748 - val_loss: 162.3943\n",
            "Epoch 239/10000\n",
            " - 1s - loss: 5.7432 - val_loss: 189.2258\n",
            "Epoch 240/10000\n",
            " - 1s - loss: 7.3912 - val_loss: 148.7523\n",
            "Epoch 241/10000\n",
            " - 1s - loss: 9.9186 - val_loss: 166.3438\n",
            "Epoch 242/10000\n",
            " - 1s - loss: 8.0367 - val_loss: 125.3852\n",
            "Epoch 243/10000\n",
            " - 1s - loss: 7.8851 - val_loss: 162.3687\n",
            "Epoch 244/10000\n",
            " - 1s - loss: 5.8133 - val_loss: 141.0162\n",
            "Epoch 245/10000\n",
            " - 1s - loss: 5.2933 - val_loss: 168.4566\n",
            "Epoch 246/10000\n",
            " - 1s - loss: 5.0422 - val_loss: 159.3067\n",
            "Epoch 247/10000\n",
            " - 1s - loss: 5.7603 - val_loss: 138.1803\n",
            "Epoch 248/10000\n",
            " - 1s - loss: 6.5320 - val_loss: 116.6206\n",
            "Epoch 249/10000\n",
            " - 1s - loss: 7.5133 - val_loss: 136.8187\n",
            "Epoch 250/10000\n",
            " - 1s - loss: 6.8530 - val_loss: 182.6592\n",
            "Epoch 251/10000\n",
            " - 1s - loss: 7.0195 - val_loss: 144.4011\n",
            "Epoch 252/10000\n",
            " - 1s - loss: 6.4009 - val_loss: 142.9551\n",
            "Epoch 253/10000\n",
            " - 1s - loss: 6.5055 - val_loss: 192.3048\n",
            "Epoch 254/10000\n",
            " - 1s - loss: 6.4589 - val_loss: 163.4887\n",
            "Epoch 255/10000\n",
            " - 1s - loss: 6.1595 - val_loss: 169.4822\n",
            "Epoch 256/10000\n",
            " - 1s - loss: 5.1540 - val_loss: 134.7638\n",
            "Epoch 257/10000\n",
            " - 1s - loss: 6.7759 - val_loss: 136.3111\n",
            "Epoch 258/10000\n",
            " - 1s - loss: 5.5395 - val_loss: 140.9710\n",
            "Epoch 259/10000\n",
            " - 1s - loss: 6.9204 - val_loss: 147.8130\n",
            "Epoch 260/10000\n",
            " - 1s - loss: 6.2512 - val_loss: 166.3007\n",
            "Epoch 261/10000\n",
            " - 1s - loss: 6.1932 - val_loss: 135.2207\n",
            "Epoch 262/10000\n",
            " - 1s - loss: 5.1293 - val_loss: 138.5584\n",
            "Epoch 263/10000\n",
            " - 1s - loss: 5.6880 - val_loss: 153.0231\n",
            "Epoch 264/10000\n",
            " - 1s - loss: 4.4451 - val_loss: 143.5992\n",
            "Epoch 265/10000\n",
            " - 1s - loss: 4.9984 - val_loss: 166.2527\n",
            "Epoch 266/10000\n",
            " - 1s - loss: 6.3233 - val_loss: 173.9013\n",
            "Epoch 267/10000\n",
            " - 1s - loss: 6.5817 - val_loss: 165.0143\n",
            "Epoch 268/10000\n",
            " - 1s - loss: 6.6839 - val_loss: 141.5257\n",
            "Epoch 269/10000\n",
            " - 1s - loss: 5.6185 - val_loss: 154.6477\n",
            "Epoch 270/10000\n",
            " - 1s - loss: 8.2278 - val_loss: 126.8719\n",
            "Epoch 271/10000\n",
            " - 1s - loss: 9.2209 - val_loss: 174.9511\n",
            "Epoch 272/10000\n",
            " - 1s - loss: 8.7602 - val_loss: 138.7152\n",
            "Epoch 273/10000\n",
            " - 1s - loss: 6.8653 - val_loss: 132.5056\n",
            "Epoch 274/10000\n",
            " - 1s - loss: 5.0818 - val_loss: 148.6988\n",
            "Epoch 275/10000\n",
            " - 1s - loss: 5.1800 - val_loss: 146.6290\n",
            "Epoch 276/10000\n",
            " - 1s - loss: 6.2571 - val_loss: 135.7645\n",
            "Epoch 277/10000\n",
            " - 1s - loss: 5.5667 - val_loss: 152.7359\n",
            "Epoch 278/10000\n",
            " - 1s - loss: 5.2070 - val_loss: 120.6193\n",
            "Epoch 279/10000\n",
            " - 1s - loss: 10.6299 - val_loss: 169.3713\n",
            "Epoch 280/10000\n",
            " - 1s - loss: 5.7716 - val_loss: 146.5336\n",
            "Epoch 281/10000\n",
            " - 1s - loss: 6.1663 - val_loss: 149.4013\n",
            "Epoch 282/10000\n",
            " - 1s - loss: 5.5308 - val_loss: 164.6729\n",
            "Epoch 283/10000\n",
            " - 1s - loss: 5.9546 - val_loss: 176.4324\n",
            "Epoch 284/10000\n",
            " - 1s - loss: 5.0157 - val_loss: 150.1000\n",
            "Epoch 285/10000\n",
            " - 1s - loss: 5.9739 - val_loss: 128.2343\n",
            "Epoch 286/10000\n",
            " - 1s - loss: 5.5906 - val_loss: 155.0644\n",
            "Epoch 287/10000\n",
            " - 1s - loss: 5.6945 - val_loss: 135.9706\n",
            "Epoch 288/10000\n",
            " - 1s - loss: 6.2560 - val_loss: 136.8342\n",
            "Epoch 289/10000\n",
            " - 1s - loss: 6.4835 - val_loss: 129.8406\n",
            "Epoch 290/10000\n",
            " - 1s - loss: 7.5116 - val_loss: 172.0957\n",
            "Epoch 291/10000\n",
            " - 1s - loss: 5.6247 - val_loss: 151.0390\n",
            "Epoch 292/10000\n",
            " - 1s - loss: 8.6333 - val_loss: 130.0565\n",
            "Epoch 293/10000\n",
            " - 1s - loss: 8.2211 - val_loss: 171.1797\n",
            "Epoch 294/10000\n",
            " - 1s - loss: 5.8695 - val_loss: 142.0976\n",
            "Epoch 295/10000\n",
            " - 1s - loss: 5.7923 - val_loss: 137.9077\n",
            "Epoch 296/10000\n",
            " - 1s - loss: 6.0228 - val_loss: 184.5429\n",
            "Epoch 297/10000\n",
            " - 1s - loss: 6.1943 - val_loss: 129.6697\n",
            "Epoch 298/10000\n",
            " - 1s - loss: 6.2014 - val_loss: 131.4038\n",
            "Epoch 299/10000\n",
            " - 1s - loss: 7.3893 - val_loss: 156.1748\n",
            "Epoch 300/10000\n",
            " - 1s - loss: 5.3986 - val_loss: 135.8853\n",
            "Epoch 301/10000\n",
            " - 1s - loss: 4.5147 - val_loss: 161.7438\n",
            "Epoch 302/10000\n",
            " - 1s - loss: 4.2785 - val_loss: 147.3414\n",
            "Epoch 303/10000\n",
            " - 1s - loss: 4.4337 - val_loss: 155.8680\n",
            "Epoch 304/10000\n",
            " - 1s - loss: 5.7393 - val_loss: 161.6866\n",
            "Epoch 305/10000\n",
            " - 1s - loss: 5.2453 - val_loss: 150.4189\n",
            "Epoch 306/10000\n",
            " - 1s - loss: 5.0593 - val_loss: 171.7395\n",
            "Epoch 307/10000\n",
            " - 1s - loss: 4.8266 - val_loss: 171.5620\n",
            "Epoch 308/10000\n",
            " - 1s - loss: 4.3463 - val_loss: 155.2150\n",
            "Epoch 309/10000\n",
            " - 1s - loss: 4.5603 - val_loss: 143.9595\n",
            "Epoch 310/10000\n",
            " - 1s - loss: 5.4974 - val_loss: 165.3497\n",
            "Epoch 311/10000\n",
            " - 1s - loss: 5.6504 - val_loss: 149.3235\n",
            "Epoch 312/10000\n",
            " - 1s - loss: 5.8771 - val_loss: 158.6914\n",
            "Epoch 313/10000\n",
            " - 1s - loss: 4.2881 - val_loss: 156.0400\n",
            "Epoch 314/10000\n",
            " - 1s - loss: 5.1704 - val_loss: 173.8586\n",
            "Epoch 315/10000\n",
            " - 1s - loss: 5.8536 - val_loss: 165.1057\n",
            "Epoch 316/10000\n",
            " - 1s - loss: 6.1259 - val_loss: 157.6762\n",
            "Epoch 317/10000\n",
            " - 1s - loss: 7.1566 - val_loss: 169.6150\n",
            "Epoch 318/10000\n",
            " - 1s - loss: 7.4718 - val_loss: 162.9126\n",
            "Epoch 319/10000\n",
            " - 1s - loss: 6.1006 - val_loss: 170.6925\n",
            "Epoch 320/10000\n",
            " - 1s - loss: 4.5113 - val_loss: 144.6417\n",
            "Epoch 321/10000\n",
            " - 1s - loss: 4.4961 - val_loss: 156.7871\n",
            "Epoch 322/10000\n",
            " - 1s - loss: 5.5766 - val_loss: 185.7115\n",
            "Epoch 323/10000\n",
            " - 1s - loss: 5.4762 - val_loss: 141.7736\n",
            "Epoch 324/10000\n",
            " - 1s - loss: 4.6928 - val_loss: 182.6981\n",
            "Epoch 325/10000\n",
            " - 1s - loss: 4.8597 - val_loss: 163.5946\n",
            "Epoch 326/10000\n",
            " - 1s - loss: 5.7834 - val_loss: 134.5130\n",
            "Epoch 327/10000\n",
            " - 1s - loss: 6.6097 - val_loss: 174.5130\n",
            "Epoch 328/10000\n",
            " - 1s - loss: 5.5912 - val_loss: 153.6605\n",
            "Epoch 329/10000\n",
            " - 1s - loss: 5.9751 - val_loss: 124.1570\n",
            "Epoch 330/10000\n",
            " - 1s - loss: 6.6776 - val_loss: 162.5623\n",
            "Epoch 331/10000\n",
            " - 1s - loss: 5.9534 - val_loss: 150.2015\n",
            "Epoch 332/10000\n",
            " - 1s - loss: 5.9469 - val_loss: 139.8099\n",
            "Epoch 333/10000\n",
            " - 1s - loss: 5.4163 - val_loss: 157.0639\n",
            "Epoch 334/10000\n",
            " - 1s - loss: 4.5322 - val_loss: 157.2621\n",
            "Epoch 335/10000\n",
            " - 1s - loss: 4.6154 - val_loss: 141.1905\n",
            "Epoch 336/10000\n",
            " - 1s - loss: 4.4713 - val_loss: 160.4791\n",
            "Epoch 337/10000\n",
            " - 1s - loss: 4.2084 - val_loss: 156.9772\n",
            "Epoch 338/10000\n",
            " - 1s - loss: 5.1444 - val_loss: 172.7310\n",
            "Epoch 339/10000\n",
            " - 1s - loss: 4.7906 - val_loss: 137.0640\n",
            "Epoch 340/10000\n",
            " - 1s - loss: 4.4658 - val_loss: 136.5148\n",
            "Epoch 341/10000\n",
            " - 1s - loss: 4.8038 - val_loss: 131.7830\n",
            "Epoch 342/10000\n",
            " - 1s - loss: 3.9973 - val_loss: 161.9415\n",
            "Epoch 343/10000\n",
            " - 1s - loss: 5.0738 - val_loss: 141.5585\n",
            "Epoch 344/10000\n",
            " - 1s - loss: 4.8139 - val_loss: 172.9904\n",
            "Epoch 345/10000\n",
            " - 1s - loss: 5.7535 - val_loss: 141.9582\n",
            "Epoch 346/10000\n",
            " - 1s - loss: 6.0803 - val_loss: 163.1007\n",
            "Epoch 347/10000\n",
            " - 1s - loss: 5.6266 - val_loss: 140.1973\n",
            "Epoch 348/10000\n",
            " - 1s - loss: 6.0182 - val_loss: 180.9114\n",
            "Epoch 349/10000\n",
            " - 1s - loss: 4.3469 - val_loss: 153.1245\n",
            "Epoch 350/10000\n",
            " - 1s - loss: 5.8499 - val_loss: 155.2564\n",
            "Epoch 351/10000\n",
            " - 1s - loss: 4.8322 - val_loss: 177.1605\n",
            "Epoch 352/10000\n",
            " - 1s - loss: 4.5444 - val_loss: 138.4941\n",
            "Epoch 353/10000\n",
            " - 1s - loss: 6.0531 - val_loss: 141.5247\n",
            "Epoch 354/10000\n",
            " - 1s - loss: 5.8608 - val_loss: 159.7859\n",
            "Epoch 355/10000\n",
            " - 1s - loss: 5.1707 - val_loss: 139.4830\n",
            "Epoch 356/10000\n",
            " - 1s - loss: 5.2672 - val_loss: 147.8733\n",
            "Epoch 357/10000\n",
            " - 1s - loss: 5.4705 - val_loss: 136.6158\n",
            "Epoch 358/10000\n",
            " - 1s - loss: 4.0471 - val_loss: 149.9193\n",
            "Epoch 359/10000\n",
            " - 1s - loss: 4.9299 - val_loss: 153.4107\n",
            "Epoch 360/10000\n",
            " - 1s - loss: 4.0319 - val_loss: 150.3938\n",
            "Epoch 361/10000\n",
            " - 1s - loss: 4.3463 - val_loss: 154.7641\n",
            "Epoch 362/10000\n",
            " - 1s - loss: 4.8428 - val_loss: 158.5799\n",
            "Epoch 363/10000\n",
            " - 1s - loss: 4.4342 - val_loss: 148.5377\n",
            "Epoch 364/10000\n",
            " - 1s - loss: 5.3770 - val_loss: 135.0921\n",
            "Epoch 365/10000\n",
            " - 1s - loss: 5.9722 - val_loss: 161.6746\n",
            "Epoch 366/10000\n",
            " - 1s - loss: 5.9442 - val_loss: 141.0890\n",
            "Epoch 367/10000\n",
            " - 1s - loss: 5.8341 - val_loss: 159.1027\n",
            "Epoch 368/10000\n",
            " - 1s - loss: 6.9272 - val_loss: 149.1286\n",
            "Epoch 369/10000\n",
            " - 1s - loss: 5.0218 - val_loss: 151.6877\n",
            "Epoch 370/10000\n",
            " - 1s - loss: 5.5864 - val_loss: 148.4251\n",
            "Epoch 371/10000\n",
            " - 1s - loss: 6.0829 - val_loss: 138.9080\n",
            "Epoch 372/10000\n",
            " - 1s - loss: 5.7113 - val_loss: 157.3596\n",
            "Epoch 373/10000\n",
            " - 1s - loss: 6.1879 - val_loss: 154.7038\n",
            "Epoch 374/10000\n",
            " - 1s - loss: 4.0078 - val_loss: 154.9935\n",
            "Epoch 375/10000\n",
            " - 1s - loss: 3.7974 - val_loss: 154.9386\n",
            "Epoch 376/10000\n",
            " - 1s - loss: 4.4753 - val_loss: 135.5803\n",
            "Epoch 377/10000\n",
            " - 1s - loss: 4.5941 - val_loss: 147.4188\n",
            "Epoch 378/10000\n",
            " - 1s - loss: 4.3144 - val_loss: 141.4980\n",
            "Epoch 379/10000\n",
            " - 1s - loss: 3.9342 - val_loss: 150.6521\n",
            "Epoch 380/10000\n",
            " - 1s - loss: 3.9556 - val_loss: 142.4517\n",
            "Epoch 381/10000\n",
            " - 1s - loss: 3.5096 - val_loss: 142.7247\n",
            "Epoch 382/10000\n",
            " - 1s - loss: 3.3874 - val_loss: 157.8375\n",
            "Epoch 383/10000\n",
            " - 1s - loss: 3.4890 - val_loss: 161.0431\n",
            "Epoch 384/10000\n",
            " - 1s - loss: 4.2247 - val_loss: 166.5744\n",
            "Epoch 385/10000\n",
            " - 1s - loss: 3.8842 - val_loss: 149.5518\n",
            "Epoch 386/10000\n",
            " - 1s - loss: 4.0124 - val_loss: 163.3419\n",
            "Epoch 387/10000\n",
            " - 1s - loss: 3.7234 - val_loss: 150.6171\n",
            "Epoch 388/10000\n",
            " - 1s - loss: 4.3293 - val_loss: 172.1424\n",
            "Epoch 389/10000\n",
            " - 1s - loss: 6.3481 - val_loss: 134.1706\n",
            "Epoch 390/10000\n",
            " - 1s - loss: 5.3965 - val_loss: 158.9145\n",
            "Epoch 391/10000\n",
            " - 1s - loss: 5.2586 - val_loss: 134.8722\n",
            "Epoch 392/10000\n",
            " - 1s - loss: 4.8394 - val_loss: 157.1856\n",
            "Epoch 393/10000\n",
            " - 1s - loss: 5.3438 - val_loss: 174.7890\n",
            "Epoch 394/10000\n",
            " - 1s - loss: 4.9751 - val_loss: 137.4035\n",
            "Epoch 395/10000\n",
            " - 1s - loss: 3.7488 - val_loss: 162.7717\n",
            "Epoch 396/10000\n",
            " - 1s - loss: 3.8513 - val_loss: 147.4359\n",
            "Epoch 397/10000\n",
            " - 1s - loss: 4.0974 - val_loss: 156.0726\n",
            "Epoch 398/10000\n",
            " - 1s - loss: 4.4855 - val_loss: 151.6990\n",
            "Epoch 399/10000\n",
            " - 1s - loss: 4.8071 - val_loss: 149.6418\n",
            "Epoch 400/10000\n",
            " - 1s - loss: 5.4438 - val_loss: 150.7516\n",
            "Epoch 401/10000\n",
            " - 1s - loss: 5.1999 - val_loss: 152.1261\n",
            "Epoch 402/10000\n",
            " - 1s - loss: 4.3728 - val_loss: 154.8956\n",
            "Epoch 403/10000\n",
            " - 1s - loss: 6.5743 - val_loss: 152.8006\n",
            "Epoch 404/10000\n",
            " - 1s - loss: 4.9259 - val_loss: 152.3056\n",
            "Epoch 405/10000\n",
            " - 1s - loss: 5.2618 - val_loss: 131.8138\n",
            "Epoch 406/10000\n",
            " - 1s - loss: 5.0479 - val_loss: 155.7112\n",
            "Epoch 407/10000\n",
            " - 1s - loss: 4.7577 - val_loss: 134.8794\n",
            "Epoch 408/10000\n",
            " - 1s - loss: 4.3277 - val_loss: 156.8505\n",
            "Epoch 409/10000\n",
            " - 1s - loss: 4.1782 - val_loss: 154.2527\n",
            "Epoch 410/10000\n",
            " - 1s - loss: 4.3143 - val_loss: 173.7843\n",
            "Epoch 411/10000\n",
            " - 1s - loss: 4.7353 - val_loss: 159.2972\n",
            "Epoch 412/10000\n",
            " - 1s - loss: 5.4053 - val_loss: 144.7046\n",
            "Epoch 413/10000\n",
            " - 1s - loss: 4.7371 - val_loss: 141.2035\n",
            "Epoch 414/10000\n",
            " - 1s - loss: 4.9427 - val_loss: 146.5013\n",
            "Epoch 415/10000\n",
            " - 1s - loss: 5.0438 - val_loss: 152.4332\n",
            "Epoch 416/10000\n",
            " - 1s - loss: 5.6563 - val_loss: 172.1839\n",
            "Epoch 417/10000\n",
            " - 1s - loss: 4.5824 - val_loss: 174.1976\n",
            "Epoch 418/10000\n",
            " - 1s - loss: 5.9298 - val_loss: 155.9011\n",
            "Epoch 419/10000\n",
            " - 1s - loss: 5.4136 - val_loss: 123.6322\n",
            "Epoch 420/10000\n",
            " - 1s - loss: 4.7436 - val_loss: 183.5096\n",
            "Epoch 421/10000\n",
            " - 1s - loss: 5.1563 - val_loss: 189.3677\n",
            "Epoch 422/10000\n",
            " - 1s - loss: 5.1348 - val_loss: 154.7858\n",
            "Epoch 423/10000\n",
            " - 1s - loss: 4.1787 - val_loss: 147.2403\n",
            "Epoch 424/10000\n",
            " - 1s - loss: 3.8687 - val_loss: 138.8449\n",
            "Epoch 425/10000\n",
            " - 1s - loss: 3.1966 - val_loss: 154.2359\n",
            "Epoch 426/10000\n",
            " - 1s - loss: 4.1293 - val_loss: 143.4437\n",
            "Epoch 427/10000\n",
            " - 1s - loss: 3.8382 - val_loss: 171.0092\n",
            "Epoch 428/10000\n",
            " - 1s - loss: 4.2898 - val_loss: 147.4120\n",
            "Epoch 429/10000\n",
            " - 1s - loss: 4.3000 - val_loss: 149.0640\n",
            "Epoch 430/10000\n",
            " - 1s - loss: 4.1669 - val_loss: 145.1693\n",
            "Epoch 431/10000\n",
            " - 1s - loss: 4.1366 - val_loss: 140.1027\n",
            "Epoch 432/10000\n",
            " - 1s - loss: 3.8827 - val_loss: 157.6402\n",
            "Epoch 433/10000\n",
            " - 1s - loss: 4.0914 - val_loss: 184.2881\n",
            "Epoch 434/10000\n",
            " - 1s - loss: 6.0022 - val_loss: 144.9987\n",
            "Epoch 435/10000\n",
            " - 1s - loss: 6.0648 - val_loss: 147.6206\n",
            "Epoch 436/10000\n",
            " - 1s - loss: 4.7529 - val_loss: 119.8147\n",
            "Epoch 437/10000\n",
            " - 1s - loss: 5.0690 - val_loss: 153.7606\n",
            "Epoch 438/10000\n",
            " - 1s - loss: 5.8871 - val_loss: 144.4471\n",
            "Epoch 439/10000\n",
            " - 1s - loss: 4.8509 - val_loss: 132.5785\n",
            "Epoch 440/10000\n",
            " - 1s - loss: 3.7858 - val_loss: 154.4142\n",
            "Epoch 441/10000\n",
            " - 1s - loss: 3.6255 - val_loss: 166.0234\n",
            "Epoch 442/10000\n",
            " - 1s - loss: 3.9542 - val_loss: 156.9745\n",
            "Epoch 443/10000\n",
            " - 1s - loss: 5.6493 - val_loss: 152.1032\n",
            "Epoch 444/10000\n",
            " - 1s - loss: 5.6845 - val_loss: 160.1485\n",
            "Epoch 445/10000\n",
            " - 1s - loss: 4.3836 - val_loss: 157.3866\n",
            "Epoch 446/10000\n",
            " - 1s - loss: 4.4059 - val_loss: 161.9614\n",
            "Epoch 447/10000\n",
            " - 1s - loss: 3.9918 - val_loss: 153.5724\n",
            "Epoch 448/10000\n",
            " - 1s - loss: 3.5331 - val_loss: 154.8279\n",
            "Epoch 449/10000\n",
            " - 1s - loss: 3.7138 - val_loss: 155.7337\n",
            "Epoch 450/10000\n",
            " - 1s - loss: 3.4918 - val_loss: 165.0837\n",
            "Epoch 451/10000\n",
            " - 1s - loss: 3.4773 - val_loss: 154.9598\n",
            "Epoch 452/10000\n",
            " - 1s - loss: 4.0816 - val_loss: 163.5338\n",
            "Epoch 453/10000\n",
            " - 1s - loss: 3.6083 - val_loss: 143.5177\n",
            "Epoch 454/10000\n",
            " - 1s - loss: 4.0586 - val_loss: 172.2941\n",
            "Epoch 455/10000\n",
            " - 1s - loss: 4.1704 - val_loss: 178.2008\n",
            "Epoch 456/10000\n",
            " - 1s - loss: 3.6106 - val_loss: 144.4637\n",
            "Epoch 457/10000\n",
            " - 1s - loss: 3.9836 - val_loss: 168.3830\n",
            "Epoch 458/10000\n",
            " - 1s - loss: 3.6501 - val_loss: 175.4276\n",
            "Epoch 459/10000\n",
            " - 1s - loss: 3.9487 - val_loss: 172.1170\n",
            "Epoch 460/10000\n",
            " - 1s - loss: 3.5494 - val_loss: 160.9086\n",
            "Epoch 461/10000\n",
            " - 1s - loss: 3.0696 - val_loss: 169.8425\n",
            "Epoch 462/10000\n",
            " - 1s - loss: 4.3933 - val_loss: 155.2420\n",
            "Epoch 463/10000\n",
            " - 1s - loss: 4.0900 - val_loss: 147.1651\n",
            "Epoch 464/10000\n",
            " - 1s - loss: 3.6672 - val_loss: 167.3007\n",
            "Epoch 465/10000\n",
            " - 1s - loss: 3.6349 - val_loss: 163.9553\n",
            "Epoch 466/10000\n",
            " - 1s - loss: 4.4173 - val_loss: 149.8917\n",
            "Epoch 467/10000\n",
            " - 1s - loss: 4.3235 - val_loss: 151.9607\n",
            "Epoch 468/10000\n",
            " - 1s - loss: 5.0105 - val_loss: 136.2777\n",
            "Epoch 469/10000\n",
            " - 1s - loss: 4.3943 - val_loss: 164.8286\n",
            "Epoch 470/10000\n",
            " - 1s - loss: 4.3310 - val_loss: 139.5570\n",
            "Epoch 471/10000\n",
            " - 1s - loss: 4.7893 - val_loss: 189.5811\n",
            "Epoch 472/10000\n",
            " - 1s - loss: 4.8575 - val_loss: 154.5173\n",
            "Epoch 473/10000\n",
            " - 1s - loss: 4.5654 - val_loss: 163.3047\n",
            "Epoch 474/10000\n",
            " - 1s - loss: 4.2581 - val_loss: 145.2337\n",
            "Epoch 475/10000\n",
            " - 1s - loss: 3.8212 - val_loss: 167.6994\n",
            "Epoch 476/10000\n",
            " - 1s - loss: 3.5628 - val_loss: 148.7960\n",
            "Epoch 477/10000\n",
            " - 1s - loss: 3.0729 - val_loss: 162.6220\n",
            "Epoch 478/10000\n",
            " - 1s - loss: 3.7064 - val_loss: 155.5973\n",
            "Epoch 479/10000\n",
            " - 1s - loss: 4.8304 - val_loss: 142.5889\n",
            "Epoch 480/10000\n",
            " - 1s - loss: 4.4220 - val_loss: 153.3067\n",
            "Epoch 481/10000\n",
            " - 1s - loss: 4.2587 - val_loss: 142.8648\n",
            "Epoch 482/10000\n",
            " - 1s - loss: 4.3865 - val_loss: 166.8813\n",
            "Epoch 483/10000\n",
            " - 1s - loss: 4.1490 - val_loss: 146.7567\n",
            "Epoch 484/10000\n",
            " - 1s - loss: 4.0818 - val_loss: 152.7288\n",
            "Epoch 485/10000\n",
            " - 1s - loss: 4.9909 - val_loss: 163.5123\n",
            "Epoch 486/10000\n",
            " - 1s - loss: 5.3251 - val_loss: 147.6994\n",
            "Epoch 487/10000\n",
            " - 1s - loss: 4.6272 - val_loss: 156.3417\n",
            "Epoch 488/10000\n",
            " - 1s - loss: 4.0463 - val_loss: 154.2466\n",
            "Epoch 489/10000\n",
            " - 1s - loss: 4.6830 - val_loss: 189.5372\n",
            "Epoch 490/10000\n",
            " - 1s - loss: 4.4225 - val_loss: 164.2868\n",
            "Epoch 491/10000\n",
            " - 1s - loss: 4.8466 - val_loss: 163.7936\n",
            "Epoch 492/10000\n",
            " - 1s - loss: 5.7704 - val_loss: 160.3158\n",
            "Epoch 493/10000\n",
            " - 1s - loss: 5.1890 - val_loss: 187.6412\n",
            "Epoch 494/10000\n",
            " - 1s - loss: 3.7885 - val_loss: 144.9404\n",
            "Epoch 495/10000\n",
            " - 1s - loss: 3.6010 - val_loss: 156.3193\n",
            "Epoch 496/10000\n",
            " - 1s - loss: 3.1132 - val_loss: 148.2929\n",
            "Epoch 497/10000\n",
            " - 1s - loss: 4.9559 - val_loss: 183.0657\n",
            "Epoch 498/10000\n",
            " - 1s - loss: 4.1195 - val_loss: 147.0192\n",
            "Epoch 499/10000\n",
            " - 1s - loss: 3.4976 - val_loss: 155.1309\n",
            "Epoch 500/10000\n",
            " - 1s - loss: 3.5135 - val_loss: 170.9302\n",
            "Epoch 501/10000\n",
            " - 1s - loss: 3.1524 - val_loss: 164.5923\n",
            "Epoch 502/10000\n",
            " - 1s - loss: 3.2318 - val_loss: 157.2220\n",
            "Epoch 503/10000\n",
            " - 1s - loss: 3.0999 - val_loss: 156.5644\n",
            "Epoch 504/10000\n",
            " - 1s - loss: 3.3120 - val_loss: 155.0815\n",
            "Epoch 505/10000\n",
            " - 1s - loss: 4.7643 - val_loss: 163.4535\n",
            "Epoch 506/10000\n",
            " - 1s - loss: 4.3847 - val_loss: 161.8696\n",
            "Epoch 507/10000\n",
            " - 1s - loss: 7.0621 - val_loss: 141.8191\n",
            "Epoch 508/10000\n",
            " - 1s - loss: 4.2939 - val_loss: 160.3674\n",
            "Epoch 509/10000\n",
            " - 1s - loss: 4.2342 - val_loss: 153.6428\n",
            "Epoch 510/10000\n",
            " - 1s - loss: 3.2499 - val_loss: 140.7198\n",
            "Epoch 511/10000\n",
            " - 1s - loss: 4.0432 - val_loss: 140.1684\n",
            "Epoch 512/10000\n",
            " - 1s - loss: 3.8547 - val_loss: 165.1419\n",
            "Epoch 513/10000\n",
            " - 1s - loss: 4.0844 - val_loss: 141.7948\n",
            "Epoch 514/10000\n",
            " - 1s - loss: 3.8719 - val_loss: 157.5724\n",
            "Epoch 515/10000\n",
            " - 1s - loss: 3.2965 - val_loss: 151.7035\n",
            "Epoch 516/10000\n",
            " - 1s - loss: 3.4963 - val_loss: 177.0620\n",
            "Epoch 517/10000\n",
            " - 1s - loss: 3.5045 - val_loss: 152.4124\n",
            "Epoch 518/10000\n",
            " - 1s - loss: 3.2528 - val_loss: 169.2368\n",
            "Epoch 519/10000\n",
            " - 1s - loss: 4.1835 - val_loss: 172.8447\n",
            "Epoch 520/10000\n",
            " - 1s - loss: 3.6962 - val_loss: 155.0757\n",
            "Epoch 521/10000\n",
            " - 1s - loss: 3.2284 - val_loss: 153.6002\n",
            "Epoch 522/10000\n",
            " - 1s - loss: 3.3427 - val_loss: 180.9114\n",
            "Epoch 523/10000\n",
            " - 1s - loss: 3.6862 - val_loss: 171.7397\n",
            "Epoch 524/10000\n",
            " - 1s - loss: 4.2251 - val_loss: 148.3570\n",
            "Epoch 525/10000\n",
            " - 1s - loss: 3.8410 - val_loss: 180.4983\n",
            "Epoch 526/10000\n",
            " - 1s - loss: 4.1010 - val_loss: 152.8515\n",
            "Epoch 527/10000\n",
            " - 1s - loss: 4.0873 - val_loss: 170.5646\n",
            "Epoch 528/10000\n",
            " - 1s - loss: 3.6039 - val_loss: 150.7420\n",
            "Epoch 529/10000\n",
            " - 1s - loss: 3.3081 - val_loss: 138.9825\n",
            "Epoch 530/10000\n",
            " - 1s - loss: 3.8916 - val_loss: 130.0746\n",
            "Epoch 531/10000\n",
            " - 1s - loss: 4.8305 - val_loss: 162.2216\n",
            "Epoch 532/10000\n",
            " - 1s - loss: 3.6495 - val_loss: 137.4467\n",
            "Epoch 533/10000\n",
            " - 1s - loss: 3.5258 - val_loss: 139.2737\n",
            "Epoch 534/10000\n",
            " - 1s - loss: 3.7977 - val_loss: 161.9749\n",
            "Epoch 535/10000\n",
            " - 1s - loss: 3.1649 - val_loss: 140.1326\n",
            "Epoch 536/10000\n",
            " - 1s - loss: 3.4340 - val_loss: 167.9295\n",
            "Epoch 537/10000\n",
            " - 1s - loss: 3.6401 - val_loss: 151.7474\n",
            "Epoch 538/10000\n",
            " - 1s - loss: 3.9605 - val_loss: 150.1460\n",
            "Epoch 539/10000\n",
            " - 1s - loss: 3.1351 - val_loss: 150.7353\n",
            "Epoch 540/10000\n",
            " - 1s - loss: 3.4510 - val_loss: 140.4374\n",
            "Epoch 541/10000\n",
            " - 1s - loss: 3.5029 - val_loss: 162.5829\n",
            "Epoch 542/10000\n",
            " - 1s - loss: 4.3779 - val_loss: 150.9616\n",
            "Epoch 543/10000\n",
            " - 1s - loss: 4.8874 - val_loss: 139.4322\n",
            "Epoch 544/10000\n",
            " - 1s - loss: 5.1402 - val_loss: 128.3388\n",
            "Epoch 545/10000\n",
            " - 1s - loss: 4.1884 - val_loss: 156.3148\n",
            "Epoch 546/10000\n",
            " - 1s - loss: 3.6856 - val_loss: 152.7577\n",
            "Epoch 547/10000\n",
            " - 1s - loss: 3.3616 - val_loss: 138.3564\n",
            "Epoch 548/10000\n",
            " - 1s - loss: 3.3714 - val_loss: 159.5109\n",
            "Epoch 549/10000\n",
            " - 1s - loss: 3.5321 - val_loss: 147.4547\n",
            "Epoch 550/10000\n",
            " - 1s - loss: 3.9369 - val_loss: 169.6594\n",
            "Epoch 551/10000\n",
            " - 1s - loss: 3.9681 - val_loss: 141.5961\n",
            "Epoch 552/10000\n",
            " - 1s - loss: 3.4240 - val_loss: 151.2923\n",
            "Epoch 553/10000\n",
            " - 1s - loss: 3.8416 - val_loss: 134.6127\n",
            "Epoch 554/10000\n",
            " - 1s - loss: 3.3358 - val_loss: 124.7700\n",
            "Epoch 555/10000\n",
            " - 1s - loss: 3.5334 - val_loss: 145.8998\n",
            "Epoch 556/10000\n",
            " - 1s - loss: 3.7604 - val_loss: 163.9481\n",
            "Epoch 557/10000\n",
            " - 1s - loss: 3.8697 - val_loss: 139.2449\n",
            "Epoch 558/10000\n",
            " - 1s - loss: 2.9759 - val_loss: 150.3062\n",
            "Epoch 559/10000\n",
            " - 1s - loss: 3.6629 - val_loss: 144.8833\n",
            "Epoch 560/10000\n",
            " - 1s - loss: 3.5459 - val_loss: 143.9855\n",
            "Epoch 561/10000\n",
            " - 1s - loss: 3.3455 - val_loss: 139.3753\n",
            "Epoch 562/10000\n",
            " - 1s - loss: 3.9629 - val_loss: 139.0627\n",
            "Epoch 563/10000\n",
            " - 1s - loss: 3.4473 - val_loss: 134.5078\n",
            "Epoch 564/10000\n",
            " - 1s - loss: 3.6565 - val_loss: 146.2516\n",
            "Epoch 565/10000\n",
            " - 1s - loss: 3.5188 - val_loss: 138.7789\n",
            "Epoch 566/10000\n",
            " - 1s - loss: 6.1821 - val_loss: 168.7762\n",
            "Epoch 567/10000\n",
            " - 1s - loss: 5.6992 - val_loss: 152.6026\n",
            "Epoch 568/10000\n",
            " - 1s - loss: 5.3487 - val_loss: 144.0104\n",
            "Epoch 569/10000\n",
            " - 1s - loss: 4.9580 - val_loss: 171.3104\n",
            "Epoch 570/10000\n",
            " - 1s - loss: 3.8553 - val_loss: 128.4934\n",
            "Epoch 571/10000\n",
            " - 1s - loss: 4.5173 - val_loss: 165.3390\n",
            "Epoch 572/10000\n",
            " - 1s - loss: 3.3165 - val_loss: 145.4736\n",
            "Epoch 573/10000\n",
            " - 1s - loss: 2.9862 - val_loss: 152.8607\n",
            "Epoch 574/10000\n",
            " - 1s - loss: 3.0327 - val_loss: 136.2737\n",
            "Epoch 575/10000\n",
            " - 1s - loss: 3.4420 - val_loss: 143.1870\n",
            "Epoch 576/10000\n",
            " - 1s - loss: 4.0939 - val_loss: 155.3508\n",
            "Epoch 577/10000\n",
            " - 1s - loss: 3.6722 - val_loss: 157.3132\n",
            "Epoch 578/10000\n",
            " - 1s - loss: 3.7986 - val_loss: 144.1529\n",
            "Epoch 579/10000\n",
            " - 1s - loss: 4.6238 - val_loss: 164.2547\n",
            "Epoch 580/10000\n",
            " - 1s - loss: 4.2690 - val_loss: 159.0814\n",
            "Epoch 581/10000\n",
            " - 1s - loss: 4.1646 - val_loss: 165.6084\n",
            "Epoch 582/10000\n",
            " - 1s - loss: 4.6787 - val_loss: 152.3321\n",
            "Epoch 583/10000\n",
            " - 1s - loss: 3.9385 - val_loss: 141.8662\n",
            "Epoch 584/10000\n",
            " - 1s - loss: 3.9316 - val_loss: 165.1563\n",
            "Epoch 585/10000\n",
            " - 1s - loss: 3.2239 - val_loss: 162.5010\n",
            "Epoch 586/10000\n",
            " - 1s - loss: 4.5916 - val_loss: 172.5680\n",
            "Epoch 587/10000\n",
            " - 1s - loss: 3.6506 - val_loss: 166.7535\n",
            "Epoch 588/10000\n",
            " - 1s - loss: 3.5880 - val_loss: 157.1167\n",
            "Epoch 589/10000\n",
            " - 1s - loss: 3.4703 - val_loss: 150.3052\n",
            "Epoch 590/10000\n",
            " - 1s - loss: 3.5989 - val_loss: 147.9395\n",
            "Epoch 591/10000\n",
            " - 1s - loss: 3.1942 - val_loss: 161.8541\n",
            "Epoch 592/10000\n",
            " - 1s - loss: 3.5421 - val_loss: 168.1797\n",
            "Epoch 593/10000\n",
            " - 1s - loss: 3.4115 - val_loss: 157.6367\n",
            "Epoch 594/10000\n",
            " - 1s - loss: 3.3601 - val_loss: 154.6011\n",
            "Epoch 595/10000\n",
            " - 1s - loss: 2.9613 - val_loss: 180.9919\n",
            "Epoch 596/10000\n",
            " - 1s - loss: 3.7842 - val_loss: 162.8043\n",
            "Epoch 597/10000\n",
            " - 1s - loss: 4.4435 - val_loss: 138.1899\n",
            "Epoch 598/10000\n",
            " - 1s - loss: 5.0210 - val_loss: 162.1470\n",
            "Epoch 599/10000\n",
            " - 1s - loss: 4.1022 - val_loss: 174.6008\n",
            "Epoch 600/10000\n",
            " - 1s - loss: 3.8836 - val_loss: 145.7529\n",
            "Epoch 601/10000\n",
            " - 1s - loss: 4.4096 - val_loss: 172.4711\n",
            "Epoch 602/10000\n",
            " - 1s - loss: 4.3439 - val_loss: 157.7457\n",
            "Epoch 603/10000\n",
            " - 1s - loss: 3.7129 - val_loss: 168.4034\n",
            "Epoch 604/10000\n",
            " - 1s - loss: 3.8487 - val_loss: 147.2554\n",
            "Epoch 605/10000\n",
            " - 1s - loss: 3.2812 - val_loss: 164.8330\n",
            "Epoch 606/10000\n",
            " - 1s - loss: 3.9061 - val_loss: 146.0719\n",
            "Epoch 607/10000\n",
            " - 1s - loss: 3.9553 - val_loss: 146.9341\n",
            "Epoch 608/10000\n",
            " - 1s - loss: 3.6162 - val_loss: 145.8912\n",
            "Epoch 609/10000\n",
            " - 1s - loss: 3.8178 - val_loss: 146.8889\n",
            "Epoch 610/10000\n",
            " - 1s - loss: 3.1915 - val_loss: 168.8037\n",
            "Epoch 611/10000\n",
            " - 1s - loss: 2.8471 - val_loss: 141.7286\n",
            "Epoch 612/10000\n",
            " - 1s - loss: 3.8066 - val_loss: 177.2352\n",
            "Epoch 613/10000\n",
            " - 1s - loss: 3.5029 - val_loss: 133.2234\n",
            "Epoch 614/10000\n",
            " - 1s - loss: 4.1563 - val_loss: 144.2271\n",
            "Epoch 615/10000\n",
            " - 1s - loss: 3.9787 - val_loss: 154.0483\n",
            "Epoch 616/10000\n",
            " - 1s - loss: 5.0456 - val_loss: 133.1063\n",
            "Epoch 617/10000\n",
            " - 1s - loss: 5.6505 - val_loss: 156.9056\n",
            "Epoch 618/10000\n",
            " - 1s - loss: 4.8612 - val_loss: 141.6064\n",
            "Epoch 619/10000\n",
            " - 1s - loss: 3.5657 - val_loss: 146.8020\n",
            "Epoch 620/10000\n",
            " - 1s - loss: 3.2032 - val_loss: 152.2716\n",
            "Epoch 621/10000\n",
            " - 1s - loss: 2.7380 - val_loss: 149.7834\n",
            "Epoch 622/10000\n",
            " - 1s - loss: 2.9528 - val_loss: 154.0917\n",
            "Epoch 623/10000\n",
            " - 1s - loss: 3.2890 - val_loss: 169.5627\n",
            "Epoch 624/10000\n",
            " - 1s - loss: 3.8527 - val_loss: 146.8592\n",
            "Epoch 625/10000\n",
            " - 1s - loss: 3.9605 - val_loss: 169.9714\n",
            "Epoch 626/10000\n",
            " - 1s - loss: 4.2160 - val_loss: 146.7845\n",
            "Epoch 627/10000\n",
            " - 1s - loss: 3.1662 - val_loss: 168.1390\n",
            "Epoch 628/10000\n",
            " - 1s - loss: 2.9774 - val_loss: 143.0286\n",
            "Epoch 629/10000\n",
            " - 1s - loss: 3.1689 - val_loss: 161.8617\n",
            "Epoch 630/10000\n",
            " - 1s - loss: 3.1171 - val_loss: 179.7126\n",
            "Epoch 631/10000\n",
            " - 1s - loss: 3.1712 - val_loss: 169.7692\n",
            "Epoch 632/10000\n",
            " - 1s - loss: 2.8450 - val_loss: 148.6368\n",
            "Epoch 633/10000\n",
            " - 1s - loss: 2.9992 - val_loss: 159.4122\n",
            "Epoch 634/10000\n",
            " - 1s - loss: 2.7227 - val_loss: 158.2796\n",
            "Epoch 635/10000\n",
            " - 1s - loss: 3.4518 - val_loss: 164.5887\n",
            "Epoch 636/10000\n",
            " - 1s - loss: 3.1695 - val_loss: 152.4464\n",
            "Epoch 637/10000\n",
            " - 1s - loss: 3.6183 - val_loss: 140.3886\n",
            "Epoch 638/10000\n",
            " - 1s - loss: 3.9526 - val_loss: 153.4680\n",
            "Epoch 639/10000\n",
            " - 1s - loss: 5.6817 - val_loss: 190.1744\n",
            "Epoch 640/10000\n",
            " - 1s - loss: 5.8393 - val_loss: 219.2711\n",
            "Epoch 641/10000\n",
            " - 1s - loss: 4.2836 - val_loss: 172.6919\n",
            "Epoch 642/10000\n",
            " - 1s - loss: 3.7668 - val_loss: 154.4554\n",
            "Epoch 643/10000\n",
            " - 1s - loss: 3.4809 - val_loss: 144.2820\n",
            "Epoch 644/10000\n",
            " - 1s - loss: 3.6886 - val_loss: 172.0631\n",
            "Epoch 645/10000\n",
            " - 1s - loss: 4.8356 - val_loss: 164.0736\n",
            "Epoch 646/10000\n",
            " - 1s - loss: 4.3658 - val_loss: 172.9589\n",
            "Epoch 647/10000\n",
            " - 1s - loss: 3.7533 - val_loss: 174.4644\n",
            "Epoch 648/10000\n",
            " - 1s - loss: 4.0498 - val_loss: 159.9641\n",
            "Epoch 649/10000\n",
            " - 1s - loss: 3.2722 - val_loss: 169.1681\n",
            "Epoch 650/10000\n",
            " - 1s - loss: 3.0508 - val_loss: 158.7968\n",
            "Epoch 651/10000\n",
            " - 1s - loss: 3.3364 - val_loss: 151.5836\n",
            "Epoch 652/10000\n",
            " - 1s - loss: 3.3342 - val_loss: 169.4920\n",
            "Epoch 653/10000\n",
            " - 1s - loss: 3.1747 - val_loss: 140.7149\n",
            "Epoch 654/10000\n",
            " - 1s - loss: 2.7785 - val_loss: 166.0223\n",
            "Epoch 655/10000\n",
            " - 1s - loss: 2.8559 - val_loss: 176.5112\n",
            "Epoch 656/10000\n",
            " - 1s - loss: 3.9292 - val_loss: 151.4718\n",
            "Epoch 657/10000\n",
            " - 1s - loss: 5.7532 - val_loss: 158.8175\n",
            "Epoch 658/10000\n",
            " - 1s - loss: 5.3946 - val_loss: 203.6282\n",
            "Epoch 659/10000\n",
            " - 1s - loss: 3.8885 - val_loss: 150.2242\n",
            "Epoch 660/10000\n",
            " - 1s - loss: 3.9329 - val_loss: 179.1394\n",
            "Epoch 661/10000\n",
            " - 1s - loss: 3.5346 - val_loss: 154.4992\n",
            "Epoch 662/10000\n",
            " - 1s - loss: 3.2325 - val_loss: 148.6985\n",
            "Epoch 663/10000\n",
            " - 1s - loss: 3.1843 - val_loss: 171.1548\n",
            "Epoch 664/10000\n",
            " - 1s - loss: 3.3983 - val_loss: 147.6858\n",
            "Epoch 665/10000\n",
            " - 1s - loss: 3.5352 - val_loss: 153.2752\n",
            "Epoch 666/10000\n",
            " - 1s - loss: 3.0854 - val_loss: 150.5731\n",
            "Epoch 667/10000\n",
            " - 1s - loss: 3.1373 - val_loss: 151.2399\n",
            "Epoch 668/10000\n",
            " - 1s - loss: 2.7751 - val_loss: 164.6764\n",
            "Epoch 669/10000\n",
            " - 1s - loss: 3.0572 - val_loss: 158.5569\n",
            "Epoch 670/10000\n",
            " - 1s - loss: 3.8315 - val_loss: 154.5093\n",
            "Epoch 671/10000\n",
            " - 1s - loss: 4.1196 - val_loss: 178.2632\n",
            "Epoch 672/10000\n",
            " - 1s - loss: 4.2263 - val_loss: 167.4455\n",
            "Epoch 673/10000\n",
            " - 1s - loss: 4.0123 - val_loss: 148.2361\n",
            "Epoch 674/10000\n",
            " - 1s - loss: 4.1499 - val_loss: 152.9269\n",
            "Epoch 675/10000\n",
            " - 1s - loss: 4.4136 - val_loss: 142.4102\n",
            "Epoch 676/10000\n",
            " - 1s - loss: 3.8912 - val_loss: 176.7569\n",
            "Epoch 677/10000\n",
            " - 1s - loss: 3.6526 - val_loss: 152.9076\n",
            "Epoch 678/10000\n",
            " - 1s - loss: 3.5042 - val_loss: 154.1773\n",
            "Epoch 679/10000\n",
            " - 1s - loss: 3.1091 - val_loss: 153.6393\n",
            "Epoch 680/10000\n",
            " - 1s - loss: 3.6084 - val_loss: 168.8650\n",
            "Epoch 681/10000\n",
            " - 1s - loss: 3.6582 - val_loss: 150.4968\n",
            "Epoch 682/10000\n",
            " - 1s - loss: 3.5501 - val_loss: 176.0017\n",
            "Epoch 683/10000\n",
            " - 1s - loss: 3.6379 - val_loss: 149.9246\n",
            "Epoch 684/10000\n",
            " - 1s - loss: 3.4757 - val_loss: 154.6093\n",
            "Epoch 685/10000\n",
            " - 1s - loss: 3.4941 - val_loss: 163.8725\n",
            "Epoch 686/10000\n",
            " - 1s - loss: 4.1170 - val_loss: 138.1739\n",
            "Epoch 687/10000\n",
            " - 1s - loss: 4.2533 - val_loss: 158.7415\n",
            "Epoch 688/10000\n",
            " - 1s - loss: 3.8490 - val_loss: 161.8412\n",
            "Epoch 689/10000\n",
            " - 1s - loss: 3.0148 - val_loss: 160.8928\n",
            "Epoch 690/10000\n",
            " - 1s - loss: 3.2072 - val_loss: 145.2674\n",
            "Epoch 691/10000\n",
            " - 1s - loss: 4.1149 - val_loss: 176.1025\n",
            "Epoch 692/10000\n",
            " - 1s - loss: 4.1014 - val_loss: 157.6024\n",
            "Epoch 693/10000\n",
            " - 1s - loss: 3.5519 - val_loss: 165.3845\n",
            "Epoch 694/10000\n",
            " - 1s - loss: 3.0443 - val_loss: 167.7977\n",
            "Epoch 695/10000\n",
            " - 1s - loss: 3.7523 - val_loss: 120.1655\n",
            "Epoch 696/10000\n",
            " - 1s - loss: 3.7287 - val_loss: 146.0016\n",
            "Epoch 697/10000\n",
            " - 1s - loss: 3.0634 - val_loss: 148.5445\n",
            "Epoch 698/10000\n",
            " - 1s - loss: 3.0383 - val_loss: 150.1374\n",
            "Epoch 699/10000\n",
            " - 1s - loss: 3.2610 - val_loss: 132.7829\n",
            "Epoch 700/10000\n",
            " - 1s - loss: 3.4803 - val_loss: 157.3038\n",
            "Epoch 701/10000\n",
            " - 1s - loss: 3.6229 - val_loss: 155.3515\n",
            "Epoch 702/10000\n",
            " - 1s - loss: 2.8666 - val_loss: 163.8695\n",
            "Epoch 703/10000\n",
            " - 1s - loss: 2.7204 - val_loss: 145.6170\n",
            "Epoch 704/10000\n",
            " - 1s - loss: 2.6998 - val_loss: 155.6019\n",
            "Epoch 705/10000\n",
            " - 1s - loss: 2.6624 - val_loss: 155.3695\n",
            "Epoch 706/10000\n",
            " - 1s - loss: 3.0814 - val_loss: 173.1940\n",
            "Epoch 707/10000\n",
            " - 1s - loss: 3.6164 - val_loss: 161.9906\n",
            "Epoch 708/10000\n",
            " - 1s - loss: 3.4163 - val_loss: 160.3899\n",
            "Epoch 709/10000\n",
            " - 1s - loss: 3.0254 - val_loss: 171.0379\n",
            "Epoch 710/10000\n",
            " - 1s - loss: 3.4490 - val_loss: 161.0103\n",
            "Epoch 711/10000\n",
            " - 1s - loss: 2.8794 - val_loss: 151.0555\n",
            "Epoch 712/10000\n",
            " - 1s - loss: 3.1330 - val_loss: 143.1662\n",
            "Epoch 713/10000\n",
            " - 1s - loss: 2.9286 - val_loss: 145.4643\n",
            "Epoch 714/10000\n",
            " - 1s - loss: 3.3218 - val_loss: 149.8875\n",
            "Epoch 715/10000\n",
            " - 1s - loss: 3.4429 - val_loss: 177.1794\n",
            "Epoch 716/10000\n",
            " - 1s - loss: 3.7090 - val_loss: 163.6053\n",
            "Epoch 717/10000\n",
            " - 1s - loss: 2.9623 - val_loss: 164.1720\n",
            "Epoch 718/10000\n",
            " - 1s - loss: 3.1421 - val_loss: 150.6404\n",
            "Epoch 719/10000\n",
            " - 1s - loss: 2.8467 - val_loss: 158.0204\n",
            "Epoch 720/10000\n",
            " - 1s - loss: 2.7756 - val_loss: 157.6180\n",
            "Epoch 721/10000\n",
            " - 1s - loss: 2.9431 - val_loss: 152.4490\n",
            "Epoch 722/10000\n",
            " - 1s - loss: 3.4810 - val_loss: 164.1328\n",
            "Epoch 723/10000\n",
            " - 1s - loss: 3.4270 - val_loss: 155.0593\n",
            "Epoch 724/10000\n",
            " - 1s - loss: 3.4796 - val_loss: 193.3115\n",
            "Epoch 725/10000\n",
            " - 1s - loss: 3.9719 - val_loss: 165.6337\n",
            "Epoch 726/10000\n",
            " - 1s - loss: 3.4993 - val_loss: 139.1712\n",
            "Epoch 727/10000\n",
            " - 1s - loss: 4.0981 - val_loss: 148.6575\n",
            "Epoch 728/10000\n",
            " - 1s - loss: 3.5289 - val_loss: 155.0345\n",
            "Epoch 729/10000\n",
            " - 1s - loss: 4.3492 - val_loss: 177.5222\n",
            "Epoch 730/10000\n",
            " - 1s - loss: 3.4845 - val_loss: 160.2656\n",
            "Epoch 731/10000\n",
            " - 1s - loss: 3.7391 - val_loss: 151.8972\n",
            "Epoch 732/10000\n",
            " - 1s - loss: 3.4907 - val_loss: 186.4001\n",
            "Epoch 733/10000\n",
            " - 1s - loss: 3.6208 - val_loss: 202.4261\n",
            "Epoch 734/10000\n",
            " - 1s - loss: 3.4930 - val_loss: 162.1954\n",
            "Epoch 735/10000\n",
            " - 1s - loss: 3.6829 - val_loss: 194.2328\n",
            "Epoch 736/10000\n",
            " - 1s - loss: 4.6719 - val_loss: 185.6636\n",
            "Epoch 737/10000\n",
            " - 1s - loss: 3.0713 - val_loss: 151.6721\n",
            "Epoch 738/10000\n",
            " - 1s - loss: 3.2964 - val_loss: 158.5086\n",
            "Epoch 739/10000\n",
            " - 1s - loss: 3.7217 - val_loss: 173.5717\n",
            "Epoch 740/10000\n",
            " - 1s - loss: 3.0935 - val_loss: 154.1047\n",
            "Epoch 741/10000\n",
            " - 1s - loss: 3.3663 - val_loss: 151.1638\n",
            "Epoch 742/10000\n",
            " - 1s - loss: 4.1563 - val_loss: 167.6709\n",
            "Epoch 743/10000\n",
            " - 1s - loss: 3.9025 - val_loss: 163.3872\n",
            "Epoch 744/10000\n",
            " - 1s - loss: 3.4475 - val_loss: 147.1774\n",
            "Epoch 745/10000\n",
            " - 1s - loss: 4.0543 - val_loss: 160.3245\n",
            "Epoch 746/10000\n",
            " - 1s - loss: 3.7892 - val_loss: 150.8720\n",
            "Epoch 747/10000\n",
            " - 1s - loss: 3.7672 - val_loss: 144.5450\n",
            "Epoch 748/10000\n",
            " - 1s - loss: 2.9217 - val_loss: 158.4508\n",
            "Epoch 749/10000\n",
            " - 1s - loss: 4.5021 - val_loss: 170.2891\n",
            "Epoch 750/10000\n",
            " - 1s - loss: 3.7183 - val_loss: 145.1218\n",
            "Epoch 751/10000\n",
            " - 1s - loss: 3.7994 - val_loss: 155.7750\n",
            "Epoch 752/10000\n",
            " - 1s - loss: 3.1312 - val_loss: 160.7892\n",
            "Epoch 753/10000\n",
            " - 1s - loss: 3.3385 - val_loss: 149.8157\n",
            "Epoch 754/10000\n",
            " - 1s - loss: 3.2673 - val_loss: 155.1408\n",
            "Epoch 755/10000\n",
            " - 1s - loss: 3.0887 - val_loss: 179.9412\n",
            "Epoch 756/10000\n",
            " - 1s - loss: 3.0308 - val_loss: 156.3959\n",
            "Epoch 757/10000\n",
            " - 1s - loss: 3.4566 - val_loss: 150.1493\n",
            "Epoch 758/10000\n",
            " - 1s - loss: 3.3317 - val_loss: 171.8035\n",
            "Epoch 759/10000\n",
            " - 1s - loss: 3.1327 - val_loss: 150.1010\n",
            "Epoch 760/10000\n",
            " - 1s - loss: 3.4360 - val_loss: 165.5488\n",
            "Epoch 761/10000\n",
            " - 1s - loss: 3.5192 - val_loss: 169.4553\n",
            "Epoch 762/10000\n",
            " - 1s - loss: 3.3741 - val_loss: 168.5371\n",
            "Epoch 763/10000\n",
            " - 1s - loss: 2.5722 - val_loss: 167.2849\n",
            "Epoch 764/10000\n",
            " - 1s - loss: 3.2148 - val_loss: 164.5254\n",
            "Epoch 765/10000\n",
            " - 1s - loss: 2.9386 - val_loss: 160.6610\n",
            "Epoch 766/10000\n",
            " - 1s - loss: 2.8251 - val_loss: 156.8412\n",
            "Epoch 767/10000\n",
            " - 1s - loss: 3.4653 - val_loss: 170.0111\n",
            "Epoch 768/10000\n",
            " - 1s - loss: 3.1152 - val_loss: 151.5062\n",
            "Epoch 769/10000\n",
            " - 1s - loss: 2.9222 - val_loss: 157.0630\n",
            "Epoch 770/10000\n",
            " - 1s - loss: 2.9204 - val_loss: 162.5884\n",
            "Epoch 771/10000\n",
            " - 1s - loss: 3.1696 - val_loss: 159.3142\n",
            "Epoch 772/10000\n",
            " - 1s - loss: 4.0139 - val_loss: 161.0521\n",
            "Epoch 773/10000\n",
            " - 1s - loss: 3.8055 - val_loss: 152.7681\n",
            "Epoch 774/10000\n",
            " - 1s - loss: 3.7221 - val_loss: 170.8007\n",
            "Epoch 775/10000\n",
            " - 1s - loss: 3.5859 - val_loss: 174.4196\n",
            "Epoch 776/10000\n",
            " - 1s - loss: 3.2466 - val_loss: 153.3228\n",
            "Epoch 777/10000\n",
            " - 1s - loss: 2.8096 - val_loss: 167.0483\n",
            "Epoch 778/10000\n",
            " - 1s - loss: 2.8150 - val_loss: 150.2068\n",
            "Epoch 779/10000\n",
            " - 1s - loss: 3.1784 - val_loss: 163.7789\n",
            "Epoch 780/10000\n",
            " - 1s - loss: 2.9356 - val_loss: 178.7183\n",
            "Epoch 781/10000\n",
            " - 1s - loss: 2.8257 - val_loss: 167.0483\n",
            "Epoch 782/10000\n",
            " - 1s - loss: 2.8052 - val_loss: 152.6887\n",
            "Epoch 783/10000\n",
            " - 1s - loss: 2.6713 - val_loss: 151.9427\n",
            "Epoch 784/10000\n",
            " - 1s - loss: 3.0669 - val_loss: 155.0067\n",
            "Epoch 785/10000\n",
            " - 1s - loss: 3.7554 - val_loss: 166.8892\n",
            "Epoch 786/10000\n",
            " - 1s - loss: 3.6712 - val_loss: 164.4258\n",
            "Epoch 787/10000\n",
            " - 1s - loss: 3.7239 - val_loss: 148.5835\n",
            "Epoch 788/10000\n",
            " - 1s - loss: 3.4947 - val_loss: 150.6478\n",
            "Epoch 789/10000\n",
            " - 1s - loss: 3.8716 - val_loss: 171.3297\n",
            "Epoch 790/10000\n",
            " - 1s - loss: 3.2521 - val_loss: 165.0812\n",
            "Epoch 791/10000\n",
            " - 1s - loss: 3.0554 - val_loss: 152.1566\n",
            "Epoch 792/10000\n",
            " - 1s - loss: 3.0098 - val_loss: 158.4186\n",
            "Epoch 793/10000\n",
            " - 1s - loss: 2.9773 - val_loss: 170.6762\n",
            "Epoch 794/10000\n",
            " - 1s - loss: 3.1213 - val_loss: 144.1547\n",
            "Epoch 795/10000\n",
            " - 1s - loss: 2.8118 - val_loss: 175.7150\n",
            "Epoch 796/10000\n",
            " - 1s - loss: 2.8561 - val_loss: 148.6301\n",
            "Epoch 797/10000\n",
            " - 1s - loss: 3.4523 - val_loss: 165.5558\n",
            "Epoch 798/10000\n",
            " - 1s - loss: 3.5670 - val_loss: 151.7142\n",
            "Epoch 799/10000\n",
            " - 1s - loss: 3.8226 - val_loss: 157.9024\n",
            "Epoch 800/10000\n",
            " - 1s - loss: 3.5782 - val_loss: 157.3002\n",
            "Epoch 801/10000\n",
            " - 1s - loss: 3.7676 - val_loss: 149.1286\n",
            "Epoch 802/10000\n",
            " - 1s - loss: 3.2521 - val_loss: 147.1283\n",
            "Epoch 803/10000\n",
            " - 1s - loss: 3.1234 - val_loss: 149.1789\n",
            "Epoch 804/10000\n",
            " - 1s - loss: 3.7670 - val_loss: 163.1085\n",
            "Epoch 805/10000\n",
            " - 1s - loss: 3.4442 - val_loss: 152.3476\n",
            "Epoch 806/10000\n",
            " - 1s - loss: 3.1039 - val_loss: 170.6104\n",
            "Epoch 807/10000\n",
            " - 1s - loss: 3.1679 - val_loss: 177.7525\n",
            "Epoch 808/10000\n",
            " - 1s - loss: 3.4635 - val_loss: 143.5601\n",
            "Epoch 809/10000\n",
            " - 1s - loss: 3.6076 - val_loss: 161.7125\n",
            "Epoch 810/10000\n",
            " - 1s - loss: 3.4033 - val_loss: 151.0021\n",
            "Epoch 811/10000\n",
            " - 1s - loss: 3.6443 - val_loss: 167.2121\n",
            "Epoch 812/10000\n",
            " - 1s - loss: 3.6273 - val_loss: 167.1951\n",
            "Epoch 813/10000\n",
            " - 1s - loss: 3.9083 - val_loss: 149.8963\n",
            "Epoch 814/10000\n",
            " - 1s - loss: 4.0503 - val_loss: 191.7054\n",
            "Epoch 815/10000\n",
            " - 1s - loss: 4.5203 - val_loss: 150.6773\n",
            "Epoch 816/10000\n",
            " - 1s - loss: 3.2457 - val_loss: 193.3407\n",
            "Epoch 817/10000\n",
            " - 1s - loss: 2.9174 - val_loss: 163.2353\n",
            "Epoch 818/10000\n",
            " - 1s - loss: 2.8117 - val_loss: 143.5152\n",
            "Epoch 819/10000\n",
            " - 1s - loss: 2.7133 - val_loss: 151.7327\n",
            "Epoch 820/10000\n",
            " - 1s - loss: 3.0100 - val_loss: 164.2515\n",
            "Epoch 821/10000\n",
            " - 1s - loss: 3.2232 - val_loss: 165.2143\n",
            "Epoch 822/10000\n",
            " - 1s - loss: 3.2364 - val_loss: 142.3837\n",
            "Epoch 823/10000\n",
            " - 1s - loss: 2.8979 - val_loss: 166.2953\n",
            "Epoch 824/10000\n",
            " - 1s - loss: 3.0221 - val_loss: 164.4782\n",
            "Epoch 825/10000\n",
            " - 1s - loss: 2.7025 - val_loss: 157.6880\n",
            "Epoch 826/10000\n",
            " - 1s - loss: 2.6676 - val_loss: 153.6840\n",
            "Epoch 827/10000\n",
            " - 1s - loss: 3.2846 - val_loss: 159.8248\n",
            "Epoch 828/10000\n",
            " - 1s - loss: 3.4169 - val_loss: 153.4454\n",
            "Epoch 829/10000\n",
            " - 1s - loss: 3.9326 - val_loss: 154.6817\n",
            "Epoch 830/10000\n",
            " - 1s - loss: 3.3803 - val_loss: 170.3140\n",
            "Epoch 831/10000\n",
            " - 1s - loss: 3.4163 - val_loss: 170.7791\n",
            "Epoch 832/10000\n",
            " - 1s - loss: 3.1681 - val_loss: 162.1968\n",
            "Epoch 833/10000\n",
            " - 1s - loss: 2.6836 - val_loss: 162.7661\n",
            "Epoch 834/10000\n",
            " - 1s - loss: 2.8376 - val_loss: 150.2613\n",
            "Epoch 835/10000\n",
            " - 1s - loss: 3.0391 - val_loss: 151.3517\n",
            "Epoch 836/10000\n",
            " - 1s - loss: 2.7439 - val_loss: 151.4334\n",
            "Epoch 837/10000\n",
            " - 1s - loss: 3.5339 - val_loss: 159.5841\n",
            "Epoch 838/10000\n",
            " - 1s - loss: 2.8546 - val_loss: 180.7825\n",
            "Epoch 839/10000\n",
            " - 1s - loss: 3.2240 - val_loss: 165.4002\n",
            "Epoch 840/10000\n",
            " - 1s - loss: 3.0005 - val_loss: 160.3837\n",
            "Epoch 841/10000\n",
            " - 1s - loss: 2.9053 - val_loss: 168.4283\n",
            "Epoch 842/10000\n",
            " - 1s - loss: 2.9246 - val_loss: 150.3921\n",
            "Epoch 843/10000\n",
            " - 1s - loss: 2.4161 - val_loss: 149.9233\n",
            "Epoch 844/10000\n",
            " - 1s - loss: 3.1252 - val_loss: 170.1372\n",
            "Epoch 845/10000\n",
            " - 1s - loss: 3.3927 - val_loss: 146.4147\n",
            "Epoch 846/10000\n",
            " - 1s - loss: 4.0021 - val_loss: 177.6416\n",
            "Epoch 847/10000\n",
            " - 1s - loss: 4.5454 - val_loss: 158.4251\n",
            "Epoch 848/10000\n",
            " - 1s - loss: 4.3719 - val_loss: 161.0196\n",
            "Epoch 849/10000\n",
            " - 1s - loss: 3.4722 - val_loss: 168.8612\n",
            "Epoch 850/10000\n",
            " - 1s - loss: 3.9116 - val_loss: 161.7077\n",
            "Epoch 851/10000\n",
            " - 1s - loss: 4.3326 - val_loss: 148.6213\n",
            "Epoch 852/10000\n",
            " - 1s - loss: 3.3389 - val_loss: 174.3808\n",
            "Epoch 853/10000\n",
            " - 1s - loss: 3.1455 - val_loss: 168.7213\n",
            "Epoch 854/10000\n",
            " - 1s - loss: 4.0759 - val_loss: 137.5719\n",
            "Epoch 855/10000\n",
            " - 1s - loss: 2.9555 - val_loss: 151.0129\n",
            "Epoch 856/10000\n",
            " - 1s - loss: 2.8135 - val_loss: 145.1694\n",
            "Epoch 857/10000\n",
            " - 1s - loss: 2.6889 - val_loss: 156.7897\n",
            "Epoch 858/10000\n",
            " - 1s - loss: 2.9443 - val_loss: 159.3172\n",
            "Epoch 859/10000\n",
            " - 1s - loss: 2.7622 - val_loss: 160.3956\n",
            "Epoch 860/10000\n",
            " - 1s - loss: 3.2172 - val_loss: 141.8132\n",
            "Epoch 861/10000\n",
            " - 1s - loss: 2.7891 - val_loss: 184.5268\n",
            "Epoch 862/10000\n",
            " - 1s - loss: 2.6358 - val_loss: 166.0172\n",
            "Epoch 863/10000\n",
            " - 1s - loss: 2.4930 - val_loss: 155.4593\n",
            "Epoch 864/10000\n",
            " - 1s - loss: 3.0839 - val_loss: 150.2553\n",
            "Epoch 865/10000\n",
            " - 1s - loss: 4.6194 - val_loss: 203.3641\n",
            "Epoch 866/10000\n",
            " - 1s - loss: 6.5912 - val_loss: 144.5063\n",
            "Epoch 867/10000\n",
            " - 1s - loss: 5.5492 - val_loss: 137.3840\n",
            "Epoch 868/10000\n",
            " - 1s - loss: 3.3508 - val_loss: 151.0002\n",
            "Epoch 869/10000\n",
            " - 1s - loss: 3.3583 - val_loss: 128.8916\n",
            "Epoch 870/10000\n",
            " - 1s - loss: 3.8447 - val_loss: 135.5547\n",
            "Epoch 871/10000\n",
            " - 1s - loss: 3.1190 - val_loss: 174.7919\n",
            "Epoch 872/10000\n",
            " - 1s - loss: 3.8351 - val_loss: 156.2940\n",
            "Epoch 873/10000\n",
            " - 1s - loss: 3.4474 - val_loss: 163.1018\n",
            "Epoch 874/10000\n",
            " - 1s - loss: 4.0682 - val_loss: 138.0012\n",
            "Epoch 875/10000\n",
            " - 1s - loss: 3.7085 - val_loss: 142.1235\n",
            "Epoch 876/10000\n",
            " - 1s - loss: 2.9248 - val_loss: 159.6106\n",
            "Epoch 877/10000\n",
            " - 1s - loss: 3.0338 - val_loss: 156.4485\n",
            "Epoch 878/10000\n",
            " - 1s - loss: 3.2212 - val_loss: 164.2217\n",
            "Epoch 879/10000\n",
            " - 1s - loss: 4.3425 - val_loss: 143.3742\n",
            "Epoch 880/10000\n",
            " - 1s - loss: 3.9284 - val_loss: 155.9762\n",
            "Epoch 881/10000\n",
            " - 1s - loss: 4.0639 - val_loss: 154.7470\n",
            "Epoch 882/10000\n",
            " - 1s - loss: 3.8964 - val_loss: 170.1715\n",
            "Epoch 883/10000\n",
            " - 1s - loss: 3.5382 - val_loss: 182.9973\n",
            "Epoch 884/10000\n",
            " - 1s - loss: 4.0947 - val_loss: 152.2769\n",
            "Epoch 885/10000\n",
            " - 1s - loss: 3.5820 - val_loss: 147.0919\n",
            "Epoch 886/10000\n",
            " - 1s - loss: 4.0832 - val_loss: 143.7322\n",
            "Epoch 887/10000\n",
            " - 1s - loss: 2.9527 - val_loss: 166.3143\n",
            "Epoch 888/10000\n",
            " - 1s - loss: 2.6592 - val_loss: 166.0840\n",
            "Epoch 889/10000\n",
            " - 1s - loss: 2.8416 - val_loss: 163.6253\n",
            "Epoch 890/10000\n",
            " - 1s - loss: 2.5199 - val_loss: 161.4570\n",
            "Epoch 891/10000\n",
            " - 1s - loss: 2.6628 - val_loss: 153.1539\n",
            "Epoch 892/10000\n",
            " - 1s - loss: 2.5355 - val_loss: 165.5212\n",
            "Epoch 893/10000\n",
            " - 1s - loss: 2.6920 - val_loss: 177.1882\n",
            "Epoch 894/10000\n",
            " - 1s - loss: 2.7134 - val_loss: 161.0382\n",
            "Epoch 895/10000\n",
            " - 1s - loss: 2.5739 - val_loss: 154.9584\n",
            "Epoch 896/10000\n",
            " - 1s - loss: 3.0095 - val_loss: 157.5451\n",
            "Epoch 897/10000\n",
            " - 1s - loss: 2.6245 - val_loss: 175.9317\n",
            "Epoch 898/10000\n",
            " - 1s - loss: 2.9198 - val_loss: 156.8680\n",
            "Epoch 899/10000\n",
            " - 1s - loss: 2.8439 - val_loss: 160.8032\n",
            "Epoch 900/10000\n",
            " - 1s - loss: 2.6230 - val_loss: 167.7067\n",
            "Epoch 901/10000\n",
            " - 1s - loss: 2.5035 - val_loss: 184.1806\n",
            "Epoch 902/10000\n",
            " - 1s - loss: 2.5549 - val_loss: 165.7408\n",
            "Epoch 903/10000\n",
            " - 1s - loss: 2.4662 - val_loss: 163.1951\n",
            "Epoch 904/10000\n",
            " - 1s - loss: 2.9871 - val_loss: 168.2522\n",
            "Epoch 905/10000\n",
            " - 1s - loss: 3.2653 - val_loss: 159.1860\n",
            "Epoch 906/10000\n",
            " - 1s - loss: 3.7852 - val_loss: 146.4167\n",
            "Epoch 907/10000\n",
            " - 1s - loss: 2.9684 - val_loss: 155.4510\n",
            "Epoch 908/10000\n",
            " - 1s - loss: 2.6978 - val_loss: 162.2432\n",
            "Epoch 909/10000\n",
            " - 1s - loss: 3.5983 - val_loss: 186.8653\n",
            "Epoch 910/10000\n",
            " - 1s - loss: 3.8263 - val_loss: 172.7591\n",
            "Epoch 911/10000\n",
            " - 1s - loss: 3.9527 - val_loss: 160.3321\n",
            "Epoch 912/10000\n",
            " - 1s - loss: 2.7422 - val_loss: 166.3388\n",
            "Epoch 913/10000\n",
            " - 1s - loss: 2.9004 - val_loss: 176.7380\n",
            "Epoch 914/10000\n",
            " - 1s - loss: 2.9298 - val_loss: 176.0366\n",
            "Epoch 915/10000\n",
            " - 1s - loss: 3.1492 - val_loss: 146.6329\n",
            "Epoch 916/10000\n",
            " - 1s - loss: 4.0084 - val_loss: 141.0335\n",
            "Epoch 917/10000\n",
            " - 1s - loss: 3.8696 - val_loss: 171.1856\n",
            "Epoch 918/10000\n",
            " - 1s - loss: 3.1909 - val_loss: 147.2312\n",
            "Epoch 919/10000\n",
            " - 1s - loss: 2.9813 - val_loss: 153.0370\n",
            "Epoch 920/10000\n",
            " - 1s - loss: 2.7764 - val_loss: 160.4483\n",
            "Epoch 921/10000\n",
            " - 1s - loss: 2.8112 - val_loss: 154.4707\n",
            "Epoch 922/10000\n",
            " - 1s - loss: 2.6577 - val_loss: 148.3281\n",
            "Epoch 923/10000\n",
            " - 1s - loss: 2.8452 - val_loss: 161.1513\n",
            "Epoch 924/10000\n",
            " - 1s - loss: 2.6267 - val_loss: 167.7077\n",
            "Epoch 925/10000\n",
            " - 1s - loss: 2.8286 - val_loss: 167.2380\n",
            "Epoch 926/10000\n",
            " - 1s - loss: 2.8641 - val_loss: 162.1955\n",
            "Epoch 927/10000\n",
            " - 1s - loss: 2.7714 - val_loss: 159.5244\n",
            "Epoch 928/10000\n",
            " - 1s - loss: 4.0776 - val_loss: 180.4028\n",
            "Epoch 929/10000\n",
            " - 1s - loss: 3.4676 - val_loss: 158.6249\n",
            "Epoch 930/10000\n",
            " - 1s - loss: 2.6922 - val_loss: 167.9215\n",
            "Epoch 931/10000\n",
            " - 1s - loss: 2.8366 - val_loss: 169.3108\n",
            "Epoch 932/10000\n",
            " - 1s - loss: 2.6454 - val_loss: 170.8670\n",
            "Epoch 933/10000\n",
            " - 1s - loss: 2.5233 - val_loss: 163.7353\n",
            "Epoch 934/10000\n",
            " - 1s - loss: 2.8684 - val_loss: 157.8139\n",
            "Epoch 935/10000\n",
            " - 1s - loss: 2.7563 - val_loss: 162.6885\n",
            "Epoch 936/10000\n",
            " - 1s - loss: 2.7554 - val_loss: 175.6494\n",
            "Epoch 937/10000\n",
            " - 1s - loss: 2.5141 - val_loss: 158.4589\n",
            "Epoch 938/10000\n",
            " - 1s - loss: 3.1110 - val_loss: 177.0417\n",
            "Epoch 939/10000\n",
            " - 1s - loss: 2.7999 - val_loss: 176.8464\n",
            "Epoch 940/10000\n",
            " - 1s - loss: 2.7078 - val_loss: 178.0003\n",
            "Epoch 941/10000\n",
            " - 1s - loss: 2.8333 - val_loss: 168.1074\n",
            "Epoch 942/10000\n",
            " - 1s - loss: 2.5172 - val_loss: 168.2199\n",
            "Epoch 943/10000\n",
            " - 1s - loss: 3.0649 - val_loss: 165.8471\n",
            "Epoch 944/10000\n",
            " - 1s - loss: 3.3320 - val_loss: 179.0187\n",
            "Epoch 945/10000\n",
            " - 1s - loss: 7.2151 - val_loss: 185.8754\n",
            "Epoch 946/10000\n",
            " - 1s - loss: 4.9285 - val_loss: 189.8307\n",
            "Epoch 947/10000\n",
            " - 1s - loss: 3.4367 - val_loss: 164.6589\n",
            "Epoch 948/10000\n",
            " - 1s - loss: 3.1776 - val_loss: 205.2557\n",
            "Epoch 949/10000\n",
            " - 1s - loss: 3.3181 - val_loss: 185.0542\n",
            "Epoch 950/10000\n",
            " - 1s - loss: 3.4435 - val_loss: 157.3621\n",
            "Epoch 951/10000\n",
            " - 1s - loss: 3.4366 - val_loss: 190.9689\n",
            "Epoch 952/10000\n",
            " - 1s - loss: 5.6078 - val_loss: 168.4984\n",
            "Epoch 953/10000\n",
            " - 1s - loss: 4.3744 - val_loss: 156.1297\n",
            "Epoch 954/10000\n",
            " - 1s - loss: 3.6547 - val_loss: 175.6373\n",
            "Epoch 955/10000\n",
            " - 1s - loss: 3.1803 - val_loss: 166.4374\n",
            "Epoch 956/10000\n",
            " - 1s - loss: 3.4054 - val_loss: 167.3273\n",
            "Epoch 957/10000\n",
            " - 1s - loss: 3.7227 - val_loss: 165.5688\n",
            "Epoch 958/10000\n",
            " - 1s - loss: 3.3882 - val_loss: 192.1402\n",
            "Epoch 959/10000\n",
            " - 1s - loss: 2.9619 - val_loss: 181.3197\n",
            "Epoch 960/10000\n",
            " - 1s - loss: 2.5840 - val_loss: 170.1252\n",
            "Epoch 961/10000\n",
            " - 1s - loss: 2.8990 - val_loss: 171.6860\n",
            "Epoch 962/10000\n",
            " - 1s - loss: 2.8930 - val_loss: 176.3177\n",
            "Epoch 963/10000\n",
            " - 1s - loss: 3.1143 - val_loss: 167.8472\n",
            "Epoch 964/10000\n",
            " - 1s - loss: 2.7617 - val_loss: 172.7244\n",
            "Epoch 965/10000\n",
            " - 1s - loss: 2.4851 - val_loss: 176.6390\n",
            "Epoch 966/10000\n",
            " - 1s - loss: 2.4137 - val_loss: 150.8400\n",
            "Epoch 967/10000\n",
            " - 1s - loss: 2.5978 - val_loss: 162.6998\n",
            "Epoch 968/10000\n",
            " - 1s - loss: 2.5934 - val_loss: 172.0680\n",
            "Epoch 969/10000\n",
            " - 1s - loss: 2.4782 - val_loss: 174.6180\n",
            "Epoch 970/10000\n",
            " - 1s - loss: 2.9934 - val_loss: 173.5108\n",
            "Epoch 971/10000\n",
            " - 1s - loss: 3.3885 - val_loss: 157.7828\n",
            "Epoch 972/10000\n",
            " - 1s - loss: 4.6731 - val_loss: 158.4592\n",
            "Epoch 973/10000\n",
            " - 1s - loss: 4.1382 - val_loss: 171.3046\n",
            "Epoch 974/10000\n",
            " - 1s - loss: 3.2304 - val_loss: 177.4863\n",
            "Epoch 975/10000\n",
            " - 1s - loss: 2.7581 - val_loss: 150.9253\n",
            "Epoch 976/10000\n",
            " - 1s - loss: 2.6419 - val_loss: 164.7556\n",
            "Epoch 977/10000\n",
            " - 1s - loss: 2.6484 - val_loss: 170.6678\n",
            "Epoch 978/10000\n",
            " - 1s - loss: 2.4319 - val_loss: 167.3618\n",
            "Epoch 979/10000\n",
            " - 1s - loss: 2.6384 - val_loss: 190.6826\n",
            "Epoch 980/10000\n",
            " - 1s - loss: 2.4320 - val_loss: 165.5504\n",
            "Epoch 981/10000\n",
            " - 1s - loss: 2.2568 - val_loss: 180.5026\n",
            "Epoch 982/10000\n",
            " - 1s - loss: 2.4307 - val_loss: 182.8064\n",
            "Epoch 983/10000\n",
            " - 1s - loss: 2.3537 - val_loss: 178.3945\n",
            "Epoch 984/10000\n",
            " - 1s - loss: 2.9468 - val_loss: 151.3065\n",
            "Epoch 985/10000\n",
            " - 1s - loss: 2.8707 - val_loss: 184.1841\n",
            "Epoch 986/10000\n",
            " - 1s - loss: 2.5008 - val_loss: 167.0009\n",
            "Epoch 987/10000\n",
            " - 1s - loss: 2.6243 - val_loss: 158.7272\n",
            "Epoch 988/10000\n",
            " - 1s - loss: 2.8656 - val_loss: 183.2500\n",
            "Epoch 989/10000\n",
            " - 1s - loss: 2.8254 - val_loss: 163.7914\n",
            "Epoch 990/10000\n",
            " - 1s - loss: 2.4065 - val_loss: 162.9559\n",
            "Epoch 991/10000\n",
            " - 1s - loss: 2.4531 - val_loss: 159.4234\n",
            "Epoch 992/10000\n",
            " - 1s - loss: 2.5889 - val_loss: 168.6906\n",
            "Epoch 993/10000\n",
            " - 1s - loss: 2.3939 - val_loss: 182.4873\n",
            "Epoch 994/10000\n",
            " - 1s - loss: 2.9070 - val_loss: 174.1990\n",
            "Epoch 995/10000\n",
            " - 1s - loss: 3.1081 - val_loss: 168.3033\n",
            "Epoch 996/10000\n",
            " - 1s - loss: 3.3416 - val_loss: 171.9205\n",
            "Epoch 997/10000\n",
            " - 1s - loss: 2.8142 - val_loss: 180.8815\n",
            "Epoch 998/10000\n",
            " - 1s - loss: 2.5758 - val_loss: 183.2530\n",
            "Epoch 999/10000\n",
            " - 1s - loss: 2.5271 - val_loss: 169.9324\n",
            "Epoch 1000/10000\n",
            " - 1s - loss: 2.4799 - val_loss: 167.0222\n",
            "Epoch 1001/10000\n",
            " - 1s - loss: 2.6751 - val_loss: 164.8640\n",
            "Epoch 1002/10000\n",
            " - 1s - loss: 2.7637 - val_loss: 173.0511\n",
            "Epoch 1003/10000\n",
            " - 1s - loss: 2.5014 - val_loss: 160.7280\n",
            "Epoch 1004/10000\n",
            " - 1s - loss: 2.6631 - val_loss: 170.4711\n",
            "Epoch 1005/10000\n",
            " - 1s - loss: 3.0221 - val_loss: 180.5112\n",
            "Epoch 1006/10000\n",
            " - 1s - loss: 3.1158 - val_loss: 153.7411\n",
            "Epoch 1007/10000\n",
            " - 1s - loss: 3.7907 - val_loss: 164.7972\n",
            "Epoch 1008/10000\n",
            " - 1s - loss: 3.1271 - val_loss: 169.5682\n",
            "Epoch 1009/10000\n",
            " - 1s - loss: 2.6483 - val_loss: 168.0951\n",
            "Epoch 1010/10000\n",
            " - 1s - loss: 2.5536 - val_loss: 171.6673\n",
            "Epoch 1011/10000\n",
            " - 1s - loss: 2.5422 - val_loss: 179.6770\n",
            "Epoch 1012/10000\n",
            " - 1s - loss: 2.2079 - val_loss: 172.5498\n",
            "Epoch 1013/10000\n",
            " - 1s - loss: 2.1561 - val_loss: 171.4308\n",
            "Epoch 1014/10000\n",
            " - 1s - loss: 2.2165 - val_loss: 162.5616\n",
            "Epoch 1015/10000\n",
            " - 1s - loss: 2.3826 - val_loss: 177.7948\n",
            "Epoch 1016/10000\n",
            " - 1s - loss: 2.6247 - val_loss: 170.2777\n",
            "Epoch 1017/10000\n",
            " - 1s - loss: 2.6025 - val_loss: 166.9480\n",
            "Epoch 1018/10000\n",
            " - 1s - loss: 2.9426 - val_loss: 163.1447\n",
            "Epoch 1019/10000\n",
            " - 1s - loss: 3.9418 - val_loss: 164.3780\n",
            "Epoch 1020/10000\n",
            " - 1s - loss: 3.6075 - val_loss: 201.5915\n",
            "Epoch 1021/10000\n",
            " - 1s - loss: 3.9440 - val_loss: 171.2706\n",
            "Epoch 1022/10000\n",
            " - 1s - loss: 3.8996 - val_loss: 158.8341\n",
            "Epoch 1023/10000\n",
            " - 1s - loss: 2.8376 - val_loss: 163.6799\n",
            "Epoch 1024/10000\n",
            " - 1s - loss: 2.6927 - val_loss: 165.0827\n",
            "Epoch 1025/10000\n",
            " - 1s - loss: 2.6711 - val_loss: 156.1885\n",
            "Epoch 1026/10000\n",
            " - 1s - loss: 2.7794 - val_loss: 178.2770\n",
            "Epoch 1027/10000\n",
            " - 1s - loss: 3.5520 - val_loss: 154.7362\n",
            "Epoch 1028/10000\n",
            " - 1s - loss: 4.2091 - val_loss: 179.5693\n",
            "Epoch 1029/10000\n",
            " - 1s - loss: 3.4346 - val_loss: 160.2656\n",
            "Epoch 1030/10000\n",
            " - 1s - loss: 4.0833 - val_loss: 171.8381\n",
            "Epoch 1031/10000\n",
            " - 1s - loss: 4.6031 - val_loss: 211.2329\n",
            "Epoch 1032/10000\n",
            " - 1s - loss: 3.5454 - val_loss: 170.0105\n",
            "Epoch 1033/10000\n",
            " - 1s - loss: 2.8265 - val_loss: 160.3993\n",
            "Epoch 1034/10000\n",
            " - 1s - loss: 2.7070 - val_loss: 183.0498\n",
            "Epoch 1035/10000\n",
            " - 1s - loss: 2.5501 - val_loss: 170.9516\n",
            "Epoch 1036/10000\n",
            " - 1s - loss: 2.8820 - val_loss: 172.5002\n",
            "Epoch 1037/10000\n",
            " - 1s - loss: 2.8416 - val_loss: 146.4346\n",
            "Epoch 1038/10000\n",
            " - 1s - loss: 2.7535 - val_loss: 161.0708\n",
            "Epoch 1039/10000\n",
            " - 1s - loss: 2.9317 - val_loss: 180.4202\n",
            "Epoch 1040/10000\n",
            " - 1s - loss: 2.6561 - val_loss: 176.6609\n",
            "Epoch 1041/10000\n",
            " - 1s - loss: 2.5909 - val_loss: 177.1174\n",
            "Epoch 1042/10000\n",
            " - 1s - loss: 2.6382 - val_loss: 182.7245\n",
            "Epoch 1043/10000\n",
            " - 1s - loss: 2.9613 - val_loss: 164.3393\n",
            "Epoch 1044/10000\n",
            " - 1s - loss: 2.5814 - val_loss: 162.1768\n",
            "Epoch 1045/10000\n",
            " - 1s - loss: 2.6473 - val_loss: 158.6230\n",
            "Epoch 1046/10000\n",
            " - 1s - loss: 2.9639 - val_loss: 170.9866\n",
            "Epoch 1047/10000\n",
            " - 1s - loss: 2.7937 - val_loss: 151.9563\n",
            "Epoch 1048/10000\n",
            " - 1s - loss: 2.6266 - val_loss: 164.8651\n",
            "Epoch 1049/10000\n",
            " - 1s - loss: 2.2511 - val_loss: 176.8495\n",
            "Epoch 1050/10000\n",
            " - 1s - loss: 2.3860 - val_loss: 163.1377\n",
            "Epoch 1051/10000\n",
            " - 1s - loss: 2.2694 - val_loss: 182.5104\n",
            "Epoch 1052/10000\n",
            " - 1s - loss: 2.6440 - val_loss: 183.8851\n",
            "Epoch 1053/10000\n",
            " - 1s - loss: 2.4231 - val_loss: 180.2517\n",
            "Epoch 1054/10000\n",
            " - 1s - loss: 2.5498 - val_loss: 178.2135\n",
            "Epoch 1055/10000\n",
            " - 1s - loss: 2.5248 - val_loss: 158.3123\n",
            "Epoch 1056/10000\n",
            " - 1s - loss: 2.5054 - val_loss: 153.3531\n",
            "Epoch 1057/10000\n",
            " - 1s - loss: 3.2876 - val_loss: 168.5890\n",
            "Epoch 1058/10000\n",
            " - 1s - loss: 2.8782 - val_loss: 167.0456\n",
            "Epoch 1059/10000\n",
            " - 1s - loss: 6.0313 - val_loss: 143.7485\n",
            "Epoch 1060/10000\n",
            " - 1s - loss: 5.2399 - val_loss: 169.4567\n",
            "Epoch 1061/10000\n",
            " - 1s - loss: 5.4563 - val_loss: 164.9684\n",
            "Epoch 1062/10000\n",
            " - 1s - loss: 3.0026 - val_loss: 175.1578\n",
            "Epoch 1063/10000\n",
            " - 1s - loss: 4.2029 - val_loss: 152.2339\n",
            "Epoch 1064/10000\n",
            " - 1s - loss: 3.2995 - val_loss: 158.4949\n",
            "Epoch 1065/10000\n",
            " - 1s - loss: 3.0398 - val_loss: 170.5332\n",
            "Epoch 1066/10000\n",
            " - 1s - loss: 2.5649 - val_loss: 161.3597\n",
            "Epoch 1067/10000\n",
            " - 1s - loss: 2.5432 - val_loss: 176.8040\n",
            "Epoch 1068/10000\n",
            " - 1s - loss: 2.6652 - val_loss: 171.0027\n",
            "Epoch 1069/10000\n",
            " - 1s - loss: 2.5706 - val_loss: 161.7965\n",
            "Epoch 1070/10000\n",
            " - 1s - loss: 3.8970 - val_loss: 184.9207\n",
            "Epoch 1071/10000\n",
            " - 1s - loss: 3.5714 - val_loss: 184.4256\n",
            "Epoch 1072/10000\n",
            " - 1s - loss: 2.6536 - val_loss: 169.9886\n",
            "Epoch 1073/10000\n",
            " - 1s - loss: 2.7092 - val_loss: 191.4516\n",
            "Epoch 1074/10000\n",
            " - 1s - loss: 2.7483 - val_loss: 161.2038\n",
            "Epoch 1075/10000\n",
            " - 1s - loss: 2.4954 - val_loss: 167.3880\n",
            "Epoch 1076/10000\n",
            " - 1s - loss: 2.4608 - val_loss: 159.0025\n",
            "Epoch 1077/10000\n",
            " - 1s - loss: 2.5194 - val_loss: 171.8485\n",
            "Epoch 1078/10000\n",
            " - 1s - loss: 2.4000 - val_loss: 158.2850\n",
            "Epoch 1079/10000\n",
            " - 1s - loss: 2.8232 - val_loss: 163.8062\n",
            "Epoch 1080/10000\n",
            " - 1s - loss: 2.3494 - val_loss: 181.9256\n",
            "Epoch 1081/10000\n",
            " - 1s - loss: 2.4141 - val_loss: 159.4402\n",
            "Epoch 1082/10000\n",
            " - 1s - loss: 2.5294 - val_loss: 156.3497\n",
            "Epoch 1083/10000\n",
            " - 1s - loss: 2.3154 - val_loss: 165.7204\n",
            "Epoch 1084/10000\n",
            " - 1s - loss: 2.6157 - val_loss: 185.7645\n",
            "Epoch 1085/10000\n",
            " - 1s - loss: 2.7323 - val_loss: 179.4076\n",
            "Epoch 1086/10000\n",
            " - 1s - loss: 2.4014 - val_loss: 175.7533\n",
            "Epoch 1087/10000\n",
            " - 1s - loss: 2.3475 - val_loss: 180.4154\n",
            "Epoch 1088/10000\n",
            " - 1s - loss: 2.5470 - val_loss: 158.4432\n",
            "Epoch 1089/10000\n",
            " - 1s - loss: 3.2718 - val_loss: 173.9788\n",
            "Epoch 1090/10000\n",
            " - 1s - loss: 3.8208 - val_loss: 166.9114\n",
            "Epoch 1091/10000\n",
            " - 1s - loss: 2.9673 - val_loss: 203.6124\n",
            "Epoch 1092/10000\n",
            " - 1s - loss: 2.9086 - val_loss: 160.3378\n",
            "Epoch 1093/10000\n",
            " - 1s - loss: 2.5628 - val_loss: 174.2948\n",
            "Epoch 1094/10000\n",
            " - 1s - loss: 2.4667 - val_loss: 163.5654\n",
            "Epoch 1095/10000\n",
            " - 1s - loss: 2.7419 - val_loss: 164.8999\n",
            "Epoch 1096/10000\n",
            " - 1s - loss: 2.6854 - val_loss: 148.0369\n",
            "Epoch 1097/10000\n",
            " - 1s - loss: 2.9593 - val_loss: 167.3223\n",
            "Epoch 1098/10000\n",
            " - 1s - loss: 2.5737 - val_loss: 165.2580\n",
            "Epoch 1099/10000\n",
            " - 1s - loss: 2.3560 - val_loss: 175.3524\n",
            "Epoch 1100/10000\n",
            " - 1s - loss: 2.4964 - val_loss: 148.0639\n",
            "Epoch 1101/10000\n",
            " - 1s - loss: 3.3494 - val_loss: 152.8348\n",
            "Epoch 1102/10000\n",
            " - 1s - loss: 3.7112 - val_loss: 164.3610\n",
            "Epoch 1103/10000\n",
            " - 1s - loss: 3.1175 - val_loss: 183.5246\n",
            "Epoch 1104/10000\n",
            " - 1s - loss: 2.5802 - val_loss: 157.1495\n",
            "Epoch 1105/10000\n",
            " - 1s - loss: 2.6983 - val_loss: 166.0373\n",
            "Epoch 1106/10000\n",
            " - 1s - loss: 2.4828 - val_loss: 166.3755\n",
            "Epoch 1107/10000\n",
            " - 1s - loss: 2.4120 - val_loss: 163.4001\n",
            "Epoch 1108/10000\n",
            " - 1s - loss: 2.5225 - val_loss: 161.2527\n",
            "Epoch 1109/10000\n",
            " - 1s - loss: 2.9088 - val_loss: 177.8306\n",
            "Epoch 1110/10000\n",
            " - 1s - loss: 2.7001 - val_loss: 167.2135\n",
            "Epoch 1111/10000\n",
            " - 1s - loss: 2.5765 - val_loss: 173.2660\n",
            "Epoch 1112/10000\n",
            " - 1s - loss: 2.6335 - val_loss: 185.3075\n",
            "Epoch 1113/10000\n",
            " - 1s - loss: 2.9227 - val_loss: 179.1190\n",
            "Epoch 1114/10000\n",
            " - 1s - loss: 3.0088 - val_loss: 152.9580\n",
            "Epoch 1115/10000\n",
            " - 1s - loss: 2.7440 - val_loss: 163.2014\n",
            "Epoch 1116/10000\n",
            " - 1s - loss: 2.8046 - val_loss: 160.8665\n",
            "Epoch 1117/10000\n",
            " - 1s - loss: 2.4431 - val_loss: 150.1926\n",
            "Epoch 1118/10000\n",
            " - 1s - loss: 2.6867 - val_loss: 159.5313\n",
            "Epoch 1119/10000\n",
            " - 1s - loss: 2.8302 - val_loss: 177.5123\n",
            "Epoch 1120/10000\n",
            " - 1s - loss: 2.8957 - val_loss: 152.6590\n",
            "Epoch 1121/10000\n",
            " - 1s - loss: 5.0382 - val_loss: 183.1048\n",
            "Epoch 1122/10000\n",
            " - 1s - loss: 5.3971 - val_loss: 162.0609\n",
            "Epoch 1123/10000\n",
            " - 1s - loss: 3.4991 - val_loss: 157.0000\n",
            "Epoch 1124/10000\n",
            " - 1s - loss: 3.1995 - val_loss: 195.8317\n",
            "Epoch 1125/10000\n",
            " - 1s - loss: 3.0683 - val_loss: 170.7257\n",
            "Epoch 1126/10000\n",
            " - 1s - loss: 2.8820 - val_loss: 168.4216\n",
            "Epoch 1127/10000\n",
            " - 1s - loss: 2.6673 - val_loss: 158.4937\n",
            "Epoch 1128/10000\n",
            " - 1s - loss: 2.9178 - val_loss: 202.7680\n",
            "Epoch 1129/10000\n",
            " - 1s - loss: 2.8876 - val_loss: 196.8210\n",
            "Epoch 1130/10000\n",
            " - 1s - loss: 4.3104 - val_loss: 175.0134\n",
            "Epoch 1131/10000\n",
            " - 1s - loss: 8.0550 - val_loss: 220.3681\n",
            "Epoch 1132/10000\n",
            " - 1s - loss: 6.0071 - val_loss: 165.6139\n",
            "Epoch 1133/10000\n",
            " - 1s - loss: 4.5946 - val_loss: 179.9010\n",
            "Epoch 1134/10000\n",
            " - 1s - loss: 2.7833 - val_loss: 160.8385\n",
            "Epoch 1135/10000\n",
            " - 1s - loss: 2.9344 - val_loss: 183.9745\n",
            "Epoch 1136/10000\n",
            " - 1s - loss: 3.0153 - val_loss: 169.0455\n",
            "Epoch 1137/10000\n",
            " - 1s - loss: 2.5591 - val_loss: 179.3775\n",
            "Epoch 1138/10000\n",
            " - 1s - loss: 2.3532 - val_loss: 178.4813\n",
            "Epoch 1139/10000\n",
            " - 1s - loss: 2.3042 - val_loss: 177.1832\n",
            "Epoch 1140/10000\n",
            " - 1s - loss: 2.5194 - val_loss: 167.4713\n",
            "Epoch 1141/10000\n",
            " - 1s - loss: 2.5097 - val_loss: 173.8170\n",
            "Epoch 1142/10000\n",
            " - 1s - loss: 2.4664 - val_loss: 192.6132\n",
            "Epoch 1143/10000\n",
            " - 1s - loss: 2.3568 - val_loss: 184.1764\n",
            "Epoch 1144/10000\n",
            " - 1s - loss: 2.8266 - val_loss: 192.6860\n",
            "Epoch 1145/10000\n",
            " - 1s - loss: 2.4956 - val_loss: 199.4457\n",
            "Epoch 1146/10000\n",
            " - 1s - loss: 2.5547 - val_loss: 176.8375\n",
            "Epoch 1147/10000\n",
            " - 1s - loss: 2.2643 - val_loss: 174.3506\n",
            "Epoch 1148/10000\n",
            " - 1s - loss: 2.3361 - val_loss: 182.2935\n",
            "Epoch 1149/10000\n",
            " - 1s - loss: 2.1913 - val_loss: 173.7835\n",
            "Epoch 1150/10000\n",
            " - 1s - loss: 2.2386 - val_loss: 176.8657\n",
            "Epoch 1151/10000\n",
            " - 1s - loss: 2.7614 - val_loss: 183.5612\n",
            "Epoch 1152/10000\n",
            " - 1s - loss: 2.4074 - val_loss: 172.2977\n",
            "Epoch 1153/10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqExCUCtwZ6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}